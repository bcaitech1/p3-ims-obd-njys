{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:58.944902Z",
     "start_time": "2021-04-22T11:06:56.623974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.4.0\n",
      "GPU 사용 가능 여부: True\n",
      "Tesla P40\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import *\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamters And Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.171980Z",
     "start_time": "2021-04-22T11:06:59.167952Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16   # Mini-batch size\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.446510Z",
     "start_time": "2021-04-22T11:06:59.443508Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 batch_size = 16,\n",
    "                 num_epochs = 20,\n",
    "                 learning_rate = 0.0001,\n",
    "                 seed = 21,\n",
    "                 val_every = 1,\n",
    "                 num_workers = 4,\n",
    "                 cutmix = False,\n",
    "                 half = False,\n",
    "                 train_resize = 224,\n",
    "                 test_resize = 256,\n",
    "                 encoder_name = 'senet154',\n",
    "                 encoder_weights = \"imagenet\",\n",
    "                 n_folds = 0, \n",
    "                 gkf = False, \n",
    "                 skf = False):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.seed = seed\n",
    "        self.val_every = val_every\n",
    "        self.num_workers = num_workers\n",
    "        self.cutmix = cutmix\n",
    "        self.half = half\n",
    "        self.train_resize = train_resize\n",
    "        self.test_resize = test_resize\n",
    "        self.encoder_name = encoder_name\n",
    "        self.encoder_weights = encoder_weights\n",
    "        self.n_folds = n_folds\n",
    "        self.gkf = gkf\n",
    "        self.skf = skf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam, half=False)->tuple:\n",
    "    '''\n",
    "    랜덤한 bounding box의 좌상단,우하단 좌표 반환\n",
    "\n",
    "    Args:\n",
    "        size (tuple): batch의 shape\n",
    "        lam (float): 자를 비율\n",
    "        half (bool): 절반으로 자름\n",
    "    '''\n",
    "\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    \n",
    "    if half==False:\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W) \n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    else:\n",
    "        bbx1 = 0\n",
    "        bby1 = 0\n",
    "        bbx2 = W//2\n",
    "        bby2 = H\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(image, mask, alpha, half=False):\n",
    "    '''\n",
    "    이미지와 마스크 컷믹스\n",
    "\n",
    "    Args:\n",
    "        image (tensor): batch 이미지\n",
    "        mask (tensor): batch 마스크\n",
    "        alpha (float): Beta Distribution의 alpha 값\n",
    "    '''\n",
    "  \n",
    "    indices = torch.randperm(image.size(0)) # 배치 크기 입력\n",
    "\n",
    "    lam = np.clip(np.random.beta(alpha, alpha),0.3,0.4)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(image.size(), lam, half)\n",
    "    new_image = image.clone()\n",
    "    new_mask = mask.clone()\n",
    "    new_image[:, :, bby1:bby2, bbx1:bbx2] = image[indices, :, bby1:bby2, bbx1:bbx2]\n",
    "    new_mask[:, bby1:bby2, bbx1:bbx2] = mask[indices, bby1:bby2, bbx1:bbx2]\n",
    "\n",
    "    return new_image, new_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, Rotate,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            Resize(320, 320),\n",
    "                            Normalize(), # 추가\n",
    "                            HorizontalFlip(p=0.5), # 추가\n",
    "                            Rotate(limit=(-30,30)), # 추가\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                           Resize(320, 320),\n",
    "                           Normalize(),\n",
    "                           HorizontalFlip(p=0.5),\n",
    "                           Rotate(limit=(-30,30)),\n",
    "                           ToTensorV2()\n",
    "                          ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           Resize(256, 256),\n",
    "                           ToTensorV2()\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['Backgroud','UNKNOWN','General trash','Paper','Paper pack','Metal',\n",
    "                    'Glass','Plastic','Styrofoam','Plastic bag','Battery','Clothing']\n",
    "data_dir = '/opt/ml/input/data/train_all.json'\n",
    "\n",
    "class TrashDataset(Dataset):\n",
    "    \"\"\"DataFrame format\"\"\"\n",
    "    def __init__(self, dataframe, data_dir, mode = 'Train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        image_id = self.df.iloc[index]['image_id']\n",
    "        path = self.df.iloc[index]['path']\n",
    "        width = self.df.iloc[index]['width']\n",
    "        height = self.df.iloc[index]['height']      \n",
    "        images = cv2.imread(path)\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        \n",
    "        if self.mode == 'Train':\n",
    "            bin = self.df.iloc[index]['bin']\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_id)\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            masks = np.zeros((height,width))\n",
    "            # Background = 0, Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for ann in anns:\n",
    "                pixel_value = ann['category_id']+1\n",
    "                masks = np.maximum(self.coco.annToMask(ann)*pixel_value, masks)\n",
    "            masks = masks.astype(np.float32)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return images, masks, bin\n",
    "        \n",
    "        if self.mode == 'Test':\n",
    "            file_name = path.split('/')[-2:]\n",
    "            file_name = \"/\".join(file_name)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return images, file_name\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Fold를 위한 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_dataloader(df, trn_idx, val_idx,fold):\n",
    "\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    data_dir = '/opt/ml/input/data/train_all.json'\n",
    "    \n",
    "    # 학습, 벨리데이션 데이터프레임 생성\n",
    "    train_df = df.iloc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_df = df.iloc[val_idx,:].reset_index(drop=True)\n",
    "    \n",
    "    # 학습, 벨리데이션 데이터셋 생성\n",
    "    print(f'\\n###### Fold:{fold} - Loading Dataset ######\\n')\n",
    "    train_ds = TrashDataset(train_df, data_dir=data_dir, transform=train_transform, mode='Train')\n",
    "    valid_ds = TrashDataset(valid_df, data_dir=data_dir, transform=val_transform, mode='Train')\n",
    "    print(f'\\n###### Fold:{fold} - Loading Dataset - DONE ######\\n')\n",
    "    \n",
    "    # 학습, 벨리데이션 데이터로더 생성\n",
    "    train_dataloader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        shuffle=True,        \n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    return train_dataloader, val_dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test를 위한 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataloader(df):\n",
    "    data_dir = '/opt/ml/input/data/test.json'\n",
    "    test_ds = TrashDataset(df,data_dir,'Test',test_transform)\n",
    "\n",
    "    tst_dataloader = torch.utils.data.DataLoader(\n",
    "                                                test_ds, \n",
    "                                                batch_size=batch_size,\n",
    "                                                num_workers=4,\n",
    "                                                shuffle=False,\n",
    "                                                pin_memory=False,\n",
    "                                                collate_fn=collate_fn,\n",
    "                                                )\n",
    "    \n",
    "    return tst_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeepLabV3',\n",
       " 'DeepLabV3Plus',\n",
       " 'FPN',\n",
       " 'Linknet',\n",
       " 'PAN',\n",
       " 'PSPNet',\n",
       " 'Unet',\n",
       " 'UnetPlusPlus',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'base',\n",
       " 'deeplabv3',\n",
       " 'encoders',\n",
       " 'fpn',\n",
       " 'linknet',\n",
       " 'pan',\n",
       " 'pspnet',\n",
       " 'unet',\n",
       " 'unetplusplus',\n",
       " 'utils']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from pprint import pprint\n",
    "dir(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(encoder_name,encoder_weights,in_channels=3,classes=12):\n",
    "    model = smp.DeepLabV3Plus(\n",
    "    encoder_name=encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=encoder_weights,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=in_channels,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=classes,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'senet154'\n",
    "encoder_weights = \"imagenet\"\n",
    "model = get_model(encoder_name,encoder_weights)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "preprocess_input = get_preprocessing_fn(encoder_name, pretrained=encoder_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:34.624277Z",
     "start_time": "2021-04-22T11:15:30.068347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape :  torch.Size([1, 3, 512, 512])\n",
      "output shape :  torch.Size([1, 12, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n",
    "\n",
    "#model = FCN8s(model = model, num_classes=12)\n",
    "x = torch.randn([1, 3, 512, 512])\n",
    "print(\"input shape : \", x.shape)\n",
    "out = model(x).to(device)\n",
    "print(\"output shape : \", out.size())\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train And Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:38.901226Z",
     "start_time": "2021-04-22T11:15:38.888195Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(fold, epoch, model, valid_dataloader, criterion, device):\n",
    "    print(f'\\n- FOLD:{fold} VALIDATION #{epoch} START - TIME:0\\n')\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    hist = np.zeros((12, 12))\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        for step, (images, masks, _) in enumerate(valid_dataloader):\n",
    "            \n",
    "            images = torch.stack(images).to(device)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long().to(device)  # (batch, channel, height, width)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            \n",
    "            outputs = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            hist = add_hist(hist, masks.detach().cpu().numpy(), outputs, n_class=12)\n",
    "            \n",
    "        acc, acc_cls, mIoU, fwavacc = label_accuracy_score(hist)    \n",
    "        avrg_loss = total_loss / cnt\n",
    "        print(f'VALIDATION #{epoch}  Average Loss: {avrg_loss:.4f}, mIoU: {mIoU:.4f}, acc : {acc:.4f}')\n",
    "    print(f'\\n- FOLD:{fold} VALIDATION #{epoch} DONE - TIME:{time.time()-start_time}\\n')\n",
    "    return avrg_loss, mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:38.201874Z",
     "start_time": "2021-04-22T11:15:38.187884Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(fold, num_epochs, model, train_dataloader, valid_dataloader, criterion, optimizer, saved_dir, val_every, device, encoder_name):\n",
    "    print(f'- Fold:{fold} Training Start - TIME:0\\n')\n",
    "    start_time = time.time()\n",
    "    best_loss = 9999999\n",
    "    best_mIoU = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        print(f'- Fold:{fold} Epoch:{epoch+1} Training Start - TIME:0\\n')\n",
    "        epoch_start=time.time()\n",
    "        for step, (images, masks, bin) in enumerate(train_dataloader):\n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "            \n",
    "            # gpu 연산을 위해 device 할당\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "#             #####################################\n",
    "#             # 50% 확률로 CutMix\n",
    "#             mix_decision = np.random.rand()\n",
    "#             if mix_decision < 0.5:\n",
    "#                 # cutmix(data, target, alpha)\n",
    "#                 images, masks = cutmix(images, masks, 1.)\n",
    "#             #####################################\n",
    "                  \n",
    "            # inference\n",
    "            outputs = model(images).to(device)\n",
    "            \n",
    "            # loss 계산 (cross entropy loss)\n",
    "            loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # step 주기에 따른 loss 출력\n",
    "            if (step + 1) % 25 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs, step+1, len(train_dataloader), loss.item()))\n",
    "        \n",
    "        # validation 주기에 따른 loss 출력 및 best model 저장\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss, mIoU = validation(fold, epoch + 1, model, valid_dataloader, criterion, device)\n",
    "#             if avrg_loss < best_loss:\n",
    "#                 print('[loss] Best performance at epoch: {}'.format(epoch + 1))\n",
    "#                 print('Save model in', saved_dir)\n",
    "#                 print()\n",
    "#                 best_loss = avrg_loss\n",
    "#                 save_model(model, saved_dir, file_name = f'fold[{fold}]_loss_best_{encoder_name}(pretrained).pt')\n",
    "            if mIoU > best_mIoU:\n",
    "                print('[mIoU] Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                print()\n",
    "                best_mIoU = mIoU\n",
    "                save_model(model, saved_dir, file_name = f'fold[{fold}]_mIoU_best_{encoder_name}(pretrained).pt')\n",
    "        print(f'- Fold:{fold} Epoch:{epoch+1} Training DONE - TIME:{time.time()-epoch_start}\\n')\n",
    "    print(f'\\n- Fold:{fold} Training DONE - TIME:{time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:41.634492Z",
     "start_time": "2021-04-22T11:15:41.627493Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 저장 함수 정의\n",
    "val_every = 1 \n",
    "    \n",
    "def save_model(model, saved_dir, file_name='fcn8s_best_model(pretrained).pt'):\n",
    "\n",
    "    import os\n",
    "\n",
    "    os.makedirs(saved_dir, exist_ok=True)\n",
    "\n",
    "    # 모델 자체를 저장\n",
    "    torch.save(model, saved_dir + '/'+ file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단일 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SingleModelTrain(df = pd.read_csv('/opt/ml/code/alldata.csv')):\n",
    "    \n",
    "    encoder_name = \"se_resnet101\"\n",
    "    encoder_weights = \"imagenet\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    saved_dir = '/opt/ml/code/saved/single'\n",
    "    \n",
    "    ####### validation 크기 조절 #######\n",
    "    train_size = int(len(df)*0.8) # 80% & 20%\n",
    "    indices = np.random.permutation(len(df))\n",
    "    trn_idx = indices[:train_size]\n",
    "    val_idx = indices[train_size:]\n",
    "    ##################################\n",
    "    \n",
    "    model = get_model(encoder_name,encoder_weights)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)\n",
    "    \n",
    "    \n",
    "    train_dataloader, valid_dataloader = get_train_valid_dataloader(df, trn_idx, val_idx, 1)\n",
    "    \n",
    "    train(fold=1,\n",
    "          num_epochs=35, \n",
    "          model=model, \n",
    "          train_dataloader=train_dataloader, \n",
    "          valid_dataloader=valid_dataloader, \n",
    "          criterion=criterion, \n",
    "          optimizer=optimizer, \n",
    "          saved_dir=saved_dir, \n",
    "          val_every=val_every, \n",
    "          device=device, \n",
    "          encoder_name=encoder_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth\" to /opt/ml/.cache/torch/checkpoints/se_resnet101-7e38fcc6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2555a83a3bf498c99ceb6f4a99c4c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/189M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Fold:1 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=5.13s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.22s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:1 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:1 Training Start - \n",
      "\n",
      "Epoch [1/35], Step [25/164], Loss: 1.8014\n",
      "Epoch [1/35], Step [50/164], Loss: 1.0995\n",
      "Epoch [1/35], Step [75/164], Loss: 1.0352\n",
      "Epoch [1/35], Step [100/164], Loss: 0.8506\n",
      "Epoch [1/35], Step [125/164], Loss: 0.8623\n",
      "Epoch [1/35], Step [150/164], Loss: 0.5426\n",
      "\n",
      "- FOLD:1 VALIDATION #1 START - TIME:0\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.6617, mIoU: 0.2173, acc : 0.8440\n",
      "\n",
      "- FOLD:1 VALIDATION #1 DONE - TIME:99.96683716773987\n",
      "\n",
      "[mIoU] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/single\n",
      "\n",
      "Epoch [2/35], Step [25/164], Loss: 0.5347\n",
      "Epoch [2/35], Step [50/164], Loss: 0.7084\n",
      "Epoch [2/35], Step [75/164], Loss: 0.5481\n",
      "Epoch [2/35], Step [100/164], Loss: 0.5075\n",
      "Epoch [2/35], Step [125/164], Loss: 0.4230\n",
      "Epoch [2/35], Step [150/164], Loss: 0.4604\n",
      "\n",
      "- FOLD:1 VALIDATION #2 START - TIME:0\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.4955, mIoU: 0.2906, acc : 0.8631\n",
      "\n",
      "- FOLD:1 VALIDATION #2 DONE - TIME:100.3226387500763\n",
      "\n",
      "[mIoU] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/single\n",
      "\n",
      "Epoch [3/35], Step [25/164], Loss: 0.3832\n"
     ]
    }
   ],
   "source": [
    "SingleModelTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group K Fold\n",
    "- by = bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GKF(dataframe=pd.read_csv('/opt/ml/code/alldata.csv'),data_dir='/opt/ml/input/data/train_all.json',n_splits=5):\n",
    "\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "\n",
    "    encoder_name = \"se_resnet101\"\n",
    "    encoder_weights = \"imagenet\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    saved_dir = '/opt/ml/code/saved/gkf'\n",
    "\n",
    "    # bin 기준 나누기\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    folds = gkf.split(dataframe.values, y=None, groups=dataframe['bin'].values)\n",
    "\n",
    "    for i, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # fold별 모델\n",
    "        model = get_model(encoder_name,encoder_weights)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 데이터 로더\n",
    "        train_dataloader, valid_dataloader = get_train_valid_dataloader(dataframe, trn_idx, val_idx,fold=i+1)\n",
    "\n",
    "        # loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # optimizer\n",
    "        optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)\n",
    "\n",
    "        # 학습\n",
    "        train(fold=i+1,\n",
    "              num_epochs=10, \n",
    "              model=model, \n",
    "              train_dataloader=train_dataloader, \n",
    "              valid_dataloader=valid_dataloader, \n",
    "              criterion=criterion, \n",
    "              optimizer=optimizer, \n",
    "              saved_dir=saved_dir, \n",
    "              val_every=val_every, \n",
    "              device=device, \n",
    "              encoder_name=encoder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Fold:1 - Loading Dataset ######\n",
      "loading annotations into memory...\n",
      "Done (t=4.12s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.25s)\n",
      "creating index...\n",
      "index created!\n",
      "###### Fold:1 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:1 Training Start- \n",
      "\n",
      "Epoch [1/1], Step [25/153], Loss: 1.5079\n",
      "Epoch [1/1], Step [50/153], Loss: 0.9618\n",
      "Epoch [1/1], Step [75/153], Loss: 0.8725\n",
      "Epoch [1/1], Step [100/153], Loss: 0.6802\n",
      "Epoch [1/1], Step [125/153], Loss: 0.5313\n",
      "Epoch [1/1], Step [150/153], Loss: 0.6674\n",
      "Start validation #1\n",
      "Validation #1  Average Loss: 0.4773, mIoU: 0.2210, acc : 0.8817\n",
      "[loss] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/gkf\n",
      "[mIoU] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/gkf\n",
      "\n",
      "- Fold:1 Training DONE -\n",
      "\n",
      "###### Fold:2 - Loading Dataset ######\n",
      "loading annotations into memory...\n",
      "Done (t=3.72s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.91s)\n",
      "creating index...\n",
      "index created!\n",
      "###### Fold:2 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:2 Training Start- \n",
      "\n",
      "Epoch [1/1], Step [25/129], Loss: 1.5111\n",
      "Epoch [1/1], Step [50/129], Loss: 1.1100\n",
      "Epoch [1/1], Step [75/129], Loss: 0.9415\n",
      "Epoch [1/1], Step [100/129], Loss: 0.7038\n",
      "Epoch [1/1], Step [125/129], Loss: 0.6600\n",
      "Start validation #1\n",
      "Validation #1  Average Loss: 0.7670, mIoU: 0.2362, acc : 0.8290\n",
      "[loss] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/gkf\n",
      "[mIoU] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/gkf\n",
      "\n",
      "- Fold:2 Training DONE -\n",
      "\n",
      "###### Fold:3 - Loading Dataset ######\n",
      "loading annotations into memory...\n",
      "Done (t=4.76s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.99s)\n",
      "creating index...\n",
      "index created!\n",
      "###### Fold:3 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:3 Training Start- \n",
      "\n",
      "Epoch [1/1], Step [25/128], Loss: 1.5081\n",
      "Epoch [1/1], Step [50/128], Loss: 1.2130\n",
      "Epoch [1/1], Step [75/128], Loss: 0.8067\n",
      "Epoch [1/1], Step [100/128], Loss: 0.8038\n",
      "Epoch [1/1], Step [125/128], Loss: 0.7642\n",
      "Start validation #1\n",
      "Validation #1  Average Loss: 0.5750, mIoU: 0.3026, acc : 0.8727\n",
      "[loss] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/gkf\n",
      "[mIoU] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/gkf\n",
      "\n",
      "- Fold:3 Training DONE -\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/opt/ml/input/data/train_all.json'\n",
    "alldata = pd.read_csv('/opt/ml/code/alldata.csv')\n",
    "\n",
    "GKF(alldata,data_dir,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K Fold\n",
    "- by = bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/train_all.json'\n",
    "\n",
    "def SKF(dataframe=pd.read_csv('/opt/ml/code/alldata.csv'),data_dir='/opt/ml/input/data/train_all.json',n_splits=5):\n",
    "\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    encoder_name = \"se_resnet101\"\n",
    "    encoder_weights = \"imagenet\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    saved_dir = '/opt/ml/code/saved/skf'\n",
    "\n",
    "    # bin 기준 나누기\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    folds = skf.split(dataframe.values, y=dataframe['bin'].values)\n",
    "\n",
    "    for i, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # fold별 모델\n",
    "        model = get_model(encoder_name,encoder_weights)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 데이터 로더\n",
    "        train_dataloader, valid_dataloader = get_train_valid_dataloader(dataframe, trn_idx, val_idx,fold=i+1)\n",
    "\n",
    "        # loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # optimizer\n",
    "        optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)\n",
    "\n",
    "        # 학습\n",
    "        train(fold=i+1,\n",
    "              num_epochs=10, \n",
    "              model=model, \n",
    "              train_dataloader=train_dataloader, \n",
    "              valid_dataloader=valid_dataloader, \n",
    "              criterion=criterion, \n",
    "              optimizer=optimizer, \n",
    "              saved_dir=saved_dir, \n",
    "              val_every=val_every, \n",
    "              device=device, \n",
    "              encoder_name=encoder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Fold:1 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=4.29s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.53s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:1 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:1 Training Start - \n",
      "\n",
      "Epoch [1/10], Step [25/164], Loss: 1.6840\n",
      "Epoch [1/10], Step [50/164], Loss: 1.1200\n",
      "Epoch [1/10], Step [75/164], Loss: 0.9277\n",
      "Epoch [1/10], Step [100/164], Loss: 0.7367\n",
      "Epoch [1/10], Step [125/164], Loss: 0.8234\n",
      "Epoch [1/10], Step [150/164], Loss: 0.5976\n",
      "\n",
      "- FOLD:1 VALIDATION #1 START -\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.6635, mIoU: 0.2747, acc : 0.8523\n",
      "\n",
      "- FOLD:1 VALIDATION #1 DONE - TIME:95.20704579353333\n",
      "\n",
      "[loss] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [2/10], Step [25/164], Loss: 0.4861\n",
      "Epoch [2/10], Step [50/164], Loss: 0.5043\n",
      "Epoch [2/10], Step [75/164], Loss: 0.4099\n",
      "Epoch [2/10], Step [100/164], Loss: 0.4142\n",
      "Epoch [2/10], Step [125/164], Loss: 0.3931\n",
      "Epoch [2/10], Step [150/164], Loss: 0.2955\n",
      "\n",
      "- FOLD:1 VALIDATION #2 START -\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.4917, mIoU: 0.3859, acc : 0.8781\n",
      "\n",
      "- FOLD:1 VALIDATION #2 DONE - TIME:96.61345624923706\n",
      "\n",
      "[loss] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [3/10], Step [25/164], Loss: 0.3692\n",
      "Epoch [3/10], Step [50/164], Loss: 0.2174\n",
      "Epoch [3/10], Step [75/164], Loss: 0.2954\n",
      "Epoch [3/10], Step [100/164], Loss: 0.3003\n",
      "Epoch [3/10], Step [125/164], Loss: 0.3074\n",
      "Epoch [3/10], Step [150/164], Loss: 0.1774\n",
      "\n",
      "- FOLD:1 VALIDATION #3 START -\n",
      "\n",
      "VALIDATION #3  Average Loss: 0.4474, mIoU: 0.3923, acc : 0.8816\n",
      "\n",
      "- FOLD:1 VALIDATION #3 DONE - TIME:102.16227436065674\n",
      "\n",
      "[loss] Best performance at epoch: 3\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [4/10], Step [25/164], Loss: 0.1583\n",
      "Epoch [4/10], Step [50/164], Loss: 0.1935\n",
      "Epoch [4/10], Step [75/164], Loss: 0.2244\n",
      "Epoch [4/10], Step [100/164], Loss: 0.3204\n",
      "Epoch [4/10], Step [125/164], Loss: 0.2628\n",
      "Epoch [4/10], Step [150/164], Loss: 0.2102\n",
      "\n",
      "- FOLD:1 VALIDATION #4 START -\n",
      "\n",
      "VALIDATION #4  Average Loss: 0.4410, mIoU: 0.4089, acc : 0.8836\n",
      "\n",
      "- FOLD:1 VALIDATION #4 DONE - TIME:96.35727334022522\n",
      "\n",
      "[loss] Best performance at epoch: 4\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [5/10], Step [25/164], Loss: 0.1884\n",
      "Epoch [5/10], Step [50/164], Loss: 0.2123\n",
      "Epoch [5/10], Step [75/164], Loss: 0.1741\n",
      "Epoch [5/10], Step [100/164], Loss: 0.1302\n",
      "Epoch [5/10], Step [125/164], Loss: 0.1703\n",
      "Epoch [5/10], Step [150/164], Loss: 0.1960\n",
      "\n",
      "- FOLD:1 VALIDATION #5 START -\n",
      "\n",
      "VALIDATION #5  Average Loss: 0.4251, mIoU: 0.4149, acc : 0.8889\n",
      "\n",
      "- FOLD:1 VALIDATION #5 DONE - TIME:96.40942358970642\n",
      "\n",
      "[loss] Best performance at epoch: 5\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [6/10], Step [25/164], Loss: 0.1160\n",
      "Epoch [6/10], Step [50/164], Loss: 0.1830\n",
      "Epoch [6/10], Step [75/164], Loss: 0.0884\n",
      "Epoch [6/10], Step [100/164], Loss: 0.1386\n",
      "Epoch [6/10], Step [125/164], Loss: 0.1453\n",
      "Epoch [6/10], Step [150/164], Loss: 0.1317\n",
      "\n",
      "- FOLD:1 VALIDATION #6 START -\n",
      "\n",
      "VALIDATION #6  Average Loss: 0.4510, mIoU: 0.4174, acc : 0.8889\n",
      "\n",
      "- FOLD:1 VALIDATION #6 DONE - TIME:96.89828658103943\n",
      "\n",
      "Epoch [7/10], Step [25/164], Loss: 0.1150\n",
      "Epoch [7/10], Step [50/164], Loss: 0.1056\n",
      "Epoch [7/10], Step [75/164], Loss: 0.1034\n",
      "Epoch [7/10], Step [100/164], Loss: 0.1503\n",
      "Epoch [7/10], Step [125/164], Loss: 0.0687\n",
      "Epoch [7/10], Step [150/164], Loss: 0.1723\n",
      "\n",
      "- FOLD:1 VALIDATION #7 START -\n",
      "\n",
      "VALIDATION #7  Average Loss: 0.4546, mIoU: 0.4096, acc : 0.8894\n",
      "\n",
      "- FOLD:1 VALIDATION #7 DONE - TIME:95.07275223731995\n",
      "\n",
      "Epoch [8/10], Step [25/164], Loss: 0.1247\n",
      "Epoch [8/10], Step [50/164], Loss: 0.0969\n",
      "Epoch [8/10], Step [75/164], Loss: 0.0910\n",
      "Epoch [8/10], Step [100/164], Loss: 0.1319\n",
      "Epoch [8/10], Step [125/164], Loss: 0.0891\n",
      "Epoch [8/10], Step [150/164], Loss: 0.0836\n",
      "\n",
      "- FOLD:1 VALIDATION #8 START -\n",
      "\n",
      "VALIDATION #8  Average Loss: 0.4386, mIoU: 0.4383, acc : 0.8937\n",
      "\n",
      "- FOLD:1 VALIDATION #8 DONE - TIME:100.10523986816406\n",
      "\n",
      "Epoch [9/10], Step [25/164], Loss: 0.0835\n",
      "Epoch [9/10], Step [50/164], Loss: 0.1018\n",
      "Epoch [9/10], Step [75/164], Loss: 0.0528\n",
      "Epoch [9/10], Step [100/164], Loss: 0.0743\n",
      "Epoch [9/10], Step [125/164], Loss: 0.1167\n",
      "Epoch [9/10], Step [150/164], Loss: 0.0659\n",
      "\n",
      "- FOLD:1 VALIDATION #9 START -\n",
      "\n",
      "VALIDATION #9  Average Loss: 0.4406, mIoU: 0.4578, acc : 0.8942\n",
      "\n",
      "- FOLD:1 VALIDATION #9 DONE - TIME:98.89220333099365\n",
      "\n",
      "Epoch [10/10], Step [25/164], Loss: 0.0633\n",
      "Epoch [10/10], Step [50/164], Loss: 0.0733\n",
      "Epoch [10/10], Step [75/164], Loss: 0.1170\n",
      "Epoch [10/10], Step [100/164], Loss: 0.0875\n",
      "Epoch [10/10], Step [125/164], Loss: 0.1112\n",
      "Epoch [10/10], Step [150/164], Loss: 0.0668\n",
      "\n",
      "- FOLD:1 VALIDATION #10 START -\n",
      "\n",
      "VALIDATION #10  Average Loss: 0.4576, mIoU: 0.4592, acc : 0.8941\n",
      "\n",
      "- FOLD:1 VALIDATION #10 DONE - TIME:100.38536238670349\n",
      "\n",
      "\n",
      "- Fold:1 Training DONE - TIME:6334.677858829498\n",
      "\n",
      "###### Fold:2 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=4.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:2 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:2 Training Start - \n",
      "\n",
      "Epoch [1/10], Step [25/164], Loss: 1.4231\n",
      "Epoch [1/10], Step [50/164], Loss: 0.9893\n",
      "Epoch [1/10], Step [75/164], Loss: 0.9067\n",
      "Epoch [1/10], Step [100/164], Loss: 0.8170\n",
      "Epoch [1/10], Step [125/164], Loss: 0.6691\n",
      "Epoch [1/10], Step [150/164], Loss: 0.7110\n",
      "\n",
      "- FOLD:2 VALIDATION #1 START -\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.5406, mIoU: 0.3648, acc : 0.8797\n",
      "\n",
      "- FOLD:2 VALIDATION #1 DONE - TIME:100.68272399902344\n",
      "\n",
      "[loss] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [2/10], Step [25/164], Loss: 0.4692\n",
      "Epoch [2/10], Step [50/164], Loss: 0.3553\n",
      "Epoch [2/10], Step [75/164], Loss: 0.5460\n",
      "Epoch [2/10], Step [100/164], Loss: 0.4581\n",
      "Epoch [2/10], Step [125/164], Loss: 0.2893\n",
      "Epoch [2/10], Step [150/164], Loss: 0.5006\n",
      "\n",
      "- FOLD:2 VALIDATION #2 START -\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.3855, mIoU: 0.4330, acc : 0.8954\n",
      "\n",
      "- FOLD:2 VALIDATION #2 DONE - TIME:100.540766954422\n",
      "\n",
      "[loss] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [3/10], Step [25/164], Loss: 0.2472\n",
      "Epoch [3/10], Step [50/164], Loss: 0.1853\n",
      "Epoch [3/10], Step [75/164], Loss: 0.2837\n",
      "Epoch [3/10], Step [100/164], Loss: 0.2294\n",
      "Epoch [3/10], Step [125/164], Loss: 0.2617\n",
      "Epoch [3/10], Step [150/164], Loss: 0.2077\n",
      "\n",
      "- FOLD:2 VALIDATION #3 START -\n",
      "\n",
      "VALIDATION #3  Average Loss: 0.3437, mIoU: 0.4455, acc : 0.9064\n",
      "\n",
      "- FOLD:2 VALIDATION #3 DONE - TIME:97.17281579971313\n",
      "\n",
      "[loss] Best performance at epoch: 3\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [4/10], Step [25/164], Loss: 0.2268\n",
      "Epoch [4/10], Step [50/164], Loss: 0.2334\n",
      "Epoch [4/10], Step [75/164], Loss: 0.1510\n",
      "Epoch [4/10], Step [100/164], Loss: 0.2921\n",
      "Epoch [4/10], Step [125/164], Loss: 0.2575\n",
      "Epoch [4/10], Step [150/164], Loss: 0.1639\n",
      "\n",
      "- FOLD:2 VALIDATION #4 START -\n",
      "\n",
      "VALIDATION #4  Average Loss: 0.3205, mIoU: 0.4737, acc : 0.9110\n",
      "\n",
      "- FOLD:2 VALIDATION #4 DONE - TIME:97.63551831245422\n",
      "\n",
      "[loss] Best performance at epoch: 4\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [5/10], Step [25/164], Loss: 0.1561\n",
      "Epoch [5/10], Step [50/164], Loss: 0.2425\n",
      "Epoch [5/10], Step [75/164], Loss: 0.1587\n",
      "Epoch [5/10], Step [100/164], Loss: 0.2319\n",
      "Epoch [5/10], Step [125/164], Loss: 0.2025\n",
      "Epoch [5/10], Step [150/164], Loss: 0.1898\n",
      "\n",
      "- FOLD:2 VALIDATION #5 START -\n",
      "\n",
      "VALIDATION #5  Average Loss: 0.3175, mIoU: 0.4857, acc : 0.9125\n",
      "\n",
      "- FOLD:2 VALIDATION #5 DONE - TIME:98.00702810287476\n",
      "\n",
      "[loss] Best performance at epoch: 5\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [6/10], Step [25/164], Loss: 0.1355\n",
      "Epoch [6/10], Step [50/164], Loss: 0.1340\n",
      "Epoch [6/10], Step [75/164], Loss: 0.1864\n",
      "Epoch [6/10], Step [100/164], Loss: 0.1011\n",
      "Epoch [6/10], Step [125/164], Loss: 0.1174\n",
      "Epoch [6/10], Step [150/164], Loss: 0.0907\n",
      "\n",
      "- FOLD:2 VALIDATION #6 START -\n",
      "\n",
      "VALIDATION #6  Average Loss: 0.3087, mIoU: 0.4857, acc : 0.9151\n",
      "\n",
      "- FOLD:2 VALIDATION #6 DONE - TIME:95.29798412322998\n",
      "\n",
      "[loss] Best performance at epoch: 6\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [7/10], Step [25/164], Loss: 0.0920\n",
      "Epoch [7/10], Step [50/164], Loss: 0.1336\n",
      "Epoch [7/10], Step [75/164], Loss: 0.1802\n",
      "Epoch [7/10], Step [100/164], Loss: 0.1432\n",
      "Epoch [7/10], Step [125/164], Loss: 0.0909\n",
      "Epoch [7/10], Step [150/164], Loss: 0.1565\n",
      "\n",
      "- FOLD:2 VALIDATION #7 START -\n",
      "\n",
      "VALIDATION #7  Average Loss: 0.3052, mIoU: 0.5295, acc : 0.9176\n",
      "\n",
      "- FOLD:2 VALIDATION #7 DONE - TIME:95.79722213745117\n",
      "\n",
      "[loss] Best performance at epoch: 7\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [8/10], Step [25/164], Loss: 0.0650\n",
      "Epoch [8/10], Step [50/164], Loss: 0.1554\n",
      "Epoch [8/10], Step [75/164], Loss: 0.2332\n",
      "Epoch [8/10], Step [100/164], Loss: 0.1349\n",
      "Epoch [8/10], Step [125/164], Loss: 0.1002\n",
      "Epoch [8/10], Step [150/164], Loss: 0.0806\n",
      "\n",
      "- FOLD:2 VALIDATION #8 START -\n",
      "\n",
      "VALIDATION #8  Average Loss: 0.3061, mIoU: 0.5351, acc : 0.9190\n",
      "\n",
      "- FOLD:2 VALIDATION #8 DONE - TIME:95.5031201839447\n",
      "\n",
      "Epoch [9/10], Step [25/164], Loss: 0.0855\n",
      "Epoch [9/10], Step [50/164], Loss: 0.0880\n",
      "Epoch [9/10], Step [75/164], Loss: 0.0956\n",
      "Epoch [9/10], Step [100/164], Loss: 0.0759\n",
      "Epoch [9/10], Step [125/164], Loss: 0.0824\n",
      "Epoch [9/10], Step [150/164], Loss: 0.0683\n",
      "\n",
      "- FOLD:2 VALIDATION #9 START -\n",
      "\n",
      "VALIDATION #9  Average Loss: 0.3524, mIoU: 0.4612, acc : 0.9123\n",
      "\n",
      "- FOLD:2 VALIDATION #9 DONE - TIME:98.01772737503052\n",
      "\n",
      "Epoch [10/10], Step [25/164], Loss: 0.0728\n",
      "Epoch [10/10], Step [50/164], Loss: 0.1366\n",
      "Epoch [10/10], Step [75/164], Loss: 0.0768\n",
      "Epoch [10/10], Step [100/164], Loss: 0.0885\n",
      "Epoch [10/10], Step [125/164], Loss: 0.0970\n",
      "Epoch [10/10], Step [150/164], Loss: 0.0637\n",
      "\n",
      "- FOLD:2 VALIDATION #10 START -\n",
      "\n",
      "VALIDATION #10  Average Loss: 0.3216, mIoU: 0.5363, acc : 0.9181\n",
      "\n",
      "- FOLD:2 VALIDATION #10 DONE - TIME:96.00961565971375\n",
      "\n",
      "\n",
      "- Fold:2 Training DONE - TIME:6327.773771762848\n",
      "\n",
      "###### Fold:3 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=4.94s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:3 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:3 Training Start - \n",
      "\n",
      "Epoch [1/10], Step [25/164], Loss: 1.5536\n",
      "Epoch [1/10], Step [50/164], Loss: 1.1785\n",
      "Epoch [1/10], Step [75/164], Loss: 0.9208\n",
      "Epoch [1/10], Step [100/164], Loss: 0.8345\n",
      "Epoch [1/10], Step [125/164], Loss: 0.8952\n",
      "Epoch [1/10], Step [150/164], Loss: 0.6619\n",
      "\n",
      "- FOLD:3 VALIDATION #1 START -\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.4537, mIoU: 0.3478, acc : 0.9088\n",
      "\n",
      "- FOLD:3 VALIDATION #1 DONE - TIME:98.12215971946716\n",
      "\n",
      "[loss] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [2/10], Step [25/164], Loss: 0.6422\n",
      "Epoch [2/10], Step [50/164], Loss: 0.4622\n",
      "Epoch [2/10], Step [75/164], Loss: 0.5119\n",
      "Epoch [2/10], Step [100/164], Loss: 0.4136\n",
      "Epoch [2/10], Step [125/164], Loss: 0.4321\n",
      "Epoch [2/10], Step [150/164], Loss: 0.3295\n",
      "\n",
      "- FOLD:3 VALIDATION #2 START -\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.3012, mIoU: 0.4286, acc : 0.9221\n",
      "\n",
      "- FOLD:3 VALIDATION #2 DONE - TIME:96.29206871986389\n",
      "\n",
      "[loss] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [3/10], Step [25/164], Loss: 0.2852\n",
      "Epoch [3/10], Step [50/164], Loss: 0.2486\n",
      "Epoch [3/10], Step [75/164], Loss: 0.3352\n",
      "Epoch [3/10], Step [100/164], Loss: 0.2003\n",
      "Epoch [3/10], Step [125/164], Loss: 0.2369\n",
      "Epoch [3/10], Step [150/164], Loss: 0.3879\n",
      "\n",
      "- FOLD:3 VALIDATION #3 START -\n",
      "\n",
      "VALIDATION #3  Average Loss: 0.2534, mIoU: 0.4740, acc : 0.9321\n",
      "\n",
      "- FOLD:3 VALIDATION #3 DONE - TIME:98.47975730895996\n",
      "\n",
      "[loss] Best performance at epoch: 3\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [4/10], Step [25/164], Loss: 0.2257\n",
      "Epoch [4/10], Step [50/164], Loss: 0.2156\n",
      "Epoch [4/10], Step [75/164], Loss: 0.2120\n",
      "Epoch [4/10], Step [100/164], Loss: 0.2119\n",
      "Epoch [4/10], Step [125/164], Loss: 0.2983\n",
      "Epoch [4/10], Step [150/164], Loss: 0.1670\n",
      "\n",
      "- FOLD:3 VALIDATION #4 START -\n",
      "\n",
      "VALIDATION #4  Average Loss: 0.2447, mIoU: 0.4807, acc : 0.9309\n",
      "\n",
      "- FOLD:3 VALIDATION #4 DONE - TIME:96.53290915489197\n",
      "\n",
      "[loss] Best performance at epoch: 4\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [5/10], Step [25/164], Loss: 0.2374\n",
      "Epoch [5/10], Step [50/164], Loss: 0.1360\n",
      "Epoch [5/10], Step [75/164], Loss: 0.1495\n",
      "Epoch [5/10], Step [100/164], Loss: 0.1763\n",
      "Epoch [5/10], Step [125/164], Loss: 0.2471\n",
      "Epoch [5/10], Step [150/164], Loss: 0.1278\n",
      "\n",
      "- FOLD:3 VALIDATION #5 START -\n",
      "\n",
      "VALIDATION #5  Average Loss: 0.2254, mIoU: 0.4859, acc : 0.9370\n",
      "\n",
      "- FOLD:3 VALIDATION #5 DONE - TIME:97.36186075210571\n",
      "\n",
      "[loss] Best performance at epoch: 5\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [6/10], Step [25/164], Loss: 0.1445\n",
      "Epoch [6/10], Step [50/164], Loss: 0.1357\n",
      "Epoch [6/10], Step [75/164], Loss: 0.1077\n",
      "Epoch [6/10], Step [100/164], Loss: 0.0971\n",
      "Epoch [6/10], Step [125/164], Loss: 0.1237\n",
      "Epoch [6/10], Step [150/164], Loss: 0.1455\n",
      "\n",
      "- FOLD:3 VALIDATION #6 START -\n",
      "\n",
      "VALIDATION #6  Average Loss: 0.2204, mIoU: 0.4937, acc : 0.9385\n",
      "\n",
      "- FOLD:3 VALIDATION #6 DONE - TIME:94.83491802215576\n",
      "\n",
      "[loss] Best performance at epoch: 6\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [7/10], Step [25/164], Loss: 0.1148\n",
      "Epoch [7/10], Step [50/164], Loss: 0.1397\n",
      "Epoch [7/10], Step [75/164], Loss: 0.0989\n",
      "Epoch [7/10], Step [100/164], Loss: 0.1236\n",
      "Epoch [7/10], Step [125/164], Loss: 0.1077\n",
      "Epoch [7/10], Step [150/164], Loss: 0.1215\n",
      "\n",
      "- FOLD:3 VALIDATION #7 START -\n",
      "\n",
      "VALIDATION #7  Average Loss: 0.2166, mIoU: 0.4908, acc : 0.9391\n",
      "\n",
      "- FOLD:3 VALIDATION #7 DONE - TIME:95.80409097671509\n",
      "\n",
      "[loss] Best performance at epoch: 7\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [8/10], Step [25/164], Loss: 0.1511\n",
      "Epoch [8/10], Step [50/164], Loss: 0.0933\n",
      "Epoch [8/10], Step [75/164], Loss: 0.1046\n",
      "Epoch [8/10], Step [100/164], Loss: 0.1139\n",
      "Epoch [8/10], Step [125/164], Loss: 0.0936\n",
      "Epoch [8/10], Step [150/164], Loss: 0.0877\n",
      "\n",
      "- FOLD:3 VALIDATION #8 START -\n",
      "\n",
      "VALIDATION #8  Average Loss: 0.2225, mIoU: 0.4863, acc : 0.9388\n",
      "\n",
      "- FOLD:3 VALIDATION #8 DONE - TIME:96.45665693283081\n",
      "\n",
      "Epoch [9/10], Step [25/164], Loss: 0.1166\n",
      "Epoch [9/10], Step [50/164], Loss: 0.1122\n",
      "Epoch [9/10], Step [75/164], Loss: 0.0806\n",
      "Epoch [9/10], Step [100/164], Loss: 0.1267\n",
      "Epoch [9/10], Step [125/164], Loss: 0.0978\n",
      "Epoch [9/10], Step [150/164], Loss: 0.1091\n",
      "\n",
      "- FOLD:3 VALIDATION #9 START -\n",
      "\n",
      "VALIDATION #9  Average Loss: 0.2273, mIoU: 0.4706, acc : 0.9387\n",
      "\n",
      "- FOLD:3 VALIDATION #9 DONE - TIME:95.75409126281738\n",
      "\n",
      "Epoch [10/10], Step [25/164], Loss: 0.1026\n",
      "Epoch [10/10], Step [50/164], Loss: 0.0771\n",
      "Epoch [10/10], Step [75/164], Loss: 0.0659\n",
      "Epoch [10/10], Step [100/164], Loss: 0.0590\n",
      "Epoch [10/10], Step [125/164], Loss: 0.0721\n",
      "Epoch [10/10], Step [150/164], Loss: 0.0764\n",
      "\n",
      "- FOLD:3 VALIDATION #10 START -\n",
      "\n",
      "VALIDATION #10  Average Loss: 0.2169, mIoU: 0.5103, acc : 0.9415\n",
      "\n",
      "- FOLD:3 VALIDATION #10 DONE - TIME:98.75920987129211\n",
      "\n",
      "\n",
      "- Fold:3 Training DONE - TIME:6261.710695266724\n",
      "\n",
      "###### Fold:4 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=3.84s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.94s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:4 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:4 Training Start - \n",
      "\n",
      "Epoch [1/10], Step [25/164], Loss: 1.4188\n",
      "Epoch [1/10], Step [50/164], Loss: 1.0892\n",
      "Epoch [1/10], Step [75/164], Loss: 0.9196\n",
      "Epoch [1/10], Step [100/164], Loss: 0.6096\n",
      "Epoch [1/10], Step [125/164], Loss: 0.5375\n",
      "Epoch [1/10], Step [150/164], Loss: 0.6591\n",
      "\n",
      "- FOLD:4 VALIDATION #1 START -\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.5062, mIoU: 0.2944, acc : 0.8856\n",
      "\n",
      "- FOLD:4 VALIDATION #1 DONE - TIME:95.30299806594849\n",
      "\n",
      "[loss] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [2/10], Step [25/164], Loss: 0.5381\n",
      "Epoch [2/10], Step [50/164], Loss: 0.3708\n",
      "Epoch [2/10], Step [75/164], Loss: 0.4686\n",
      "Epoch [2/10], Step [100/164], Loss: 0.3449\n",
      "Epoch [2/10], Step [125/164], Loss: 0.3921\n",
      "Epoch [2/10], Step [150/164], Loss: 0.2641\n",
      "\n",
      "- FOLD:4 VALIDATION #2 START -\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.3361, mIoU: 0.4396, acc : 0.9116\n",
      "\n",
      "- FOLD:4 VALIDATION #2 DONE - TIME:97.93006205558777\n",
      "\n",
      "[loss] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [3/10], Step [25/164], Loss: 0.2462\n",
      "Epoch [3/10], Step [50/164], Loss: 0.4747\n",
      "Epoch [3/10], Step [75/164], Loss: 0.2745\n",
      "Epoch [3/10], Step [100/164], Loss: 0.2139\n",
      "Epoch [3/10], Step [125/164], Loss: 0.2390\n",
      "Epoch [3/10], Step [150/164], Loss: 0.2521\n",
      "\n",
      "- FOLD:4 VALIDATION #3 START -\n",
      "\n",
      "VALIDATION #3  Average Loss: 0.3010, mIoU: 0.4483, acc : 0.9161\n",
      "\n",
      "- FOLD:4 VALIDATION #3 DONE - TIME:95.60326957702637\n",
      "\n",
      "[loss] Best performance at epoch: 3\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [4/10], Step [25/164], Loss: 0.2401\n",
      "Epoch [4/10], Step [50/164], Loss: 0.2374\n",
      "Epoch [4/10], Step [75/164], Loss: 0.2798\n",
      "Epoch [4/10], Step [100/164], Loss: 0.2029\n",
      "Epoch [4/10], Step [125/164], Loss: 0.2129\n",
      "Epoch [4/10], Step [150/164], Loss: 0.1858\n",
      "\n",
      "- FOLD:4 VALIDATION #4 START -\n",
      "\n",
      "VALIDATION #4  Average Loss: 0.2835, mIoU: 0.4573, acc : 0.9209\n",
      "\n",
      "- FOLD:4 VALIDATION #4 DONE - TIME:95.4197998046875\n",
      "\n",
      "[loss] Best performance at epoch: 4\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [5/10], Step [25/164], Loss: 0.1392\n",
      "Epoch [5/10], Step [50/164], Loss: 0.2085\n",
      "Epoch [5/10], Step [75/164], Loss: 0.1308\n",
      "Epoch [5/10], Step [100/164], Loss: 0.1363\n",
      "Epoch [5/10], Step [125/164], Loss: 0.1647\n",
      "Epoch [5/10], Step [150/164], Loss: 0.1228\n",
      "\n",
      "- FOLD:4 VALIDATION #5 START -\n",
      "\n",
      "VALIDATION #5  Average Loss: 0.2830, mIoU: 0.4505, acc : 0.9228\n",
      "\n",
      "- FOLD:4 VALIDATION #5 DONE - TIME:95.34704113006592\n",
      "\n",
      "[loss] Best performance at epoch: 5\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [6/10], Step [25/164], Loss: 0.1697\n",
      "Epoch [6/10], Step [50/164], Loss: 0.1111\n",
      "Epoch [6/10], Step [75/164], Loss: 0.1838\n",
      "Epoch [6/10], Step [100/164], Loss: 0.1996\n",
      "Epoch [6/10], Step [125/164], Loss: 0.1731\n",
      "Epoch [6/10], Step [150/164], Loss: 0.1403\n",
      "\n",
      "- FOLD:4 VALIDATION #6 START -\n",
      "\n",
      "VALIDATION #6  Average Loss: 0.2754, mIoU: 0.4596, acc : 0.9228\n",
      "\n",
      "- FOLD:4 VALIDATION #6 DONE - TIME:103.1193459033966\n",
      "\n",
      "[loss] Best performance at epoch: 6\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [7/10], Step [25/164], Loss: 0.1276\n",
      "Epoch [7/10], Step [50/164], Loss: 0.1900\n",
      "Epoch [7/10], Step [75/164], Loss: 0.0925\n",
      "Epoch [7/10], Step [100/164], Loss: 0.0899\n",
      "Epoch [7/10], Step [125/164], Loss: 0.1386\n",
      "Epoch [7/10], Step [150/164], Loss: 0.1135\n",
      "\n",
      "- FOLD:4 VALIDATION #7 START -\n",
      "\n",
      "VALIDATION #7  Average Loss: 0.2910, mIoU: 0.4633, acc : 0.9225\n",
      "\n",
      "- FOLD:4 VALIDATION #7 DONE - TIME:97.29137659072876\n",
      "\n",
      "Epoch [8/10], Step [25/164], Loss: 0.1178\n",
      "Epoch [8/10], Step [50/164], Loss: 0.0782\n",
      "Epoch [8/10], Step [75/164], Loss: 0.0855\n",
      "Epoch [8/10], Step [100/164], Loss: 0.1940\n",
      "Epoch [8/10], Step [125/164], Loss: 0.1290\n",
      "Epoch [8/10], Step [150/164], Loss: 0.0884\n",
      "\n",
      "- FOLD:4 VALIDATION #8 START -\n",
      "\n",
      "VALIDATION #8  Average Loss: 0.2707, mIoU: 0.4900, acc : 0.9274\n",
      "\n",
      "- FOLD:4 VALIDATION #8 DONE - TIME:96.03657698631287\n",
      "\n",
      "[loss] Best performance at epoch: 8\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [9/10], Step [25/164], Loss: 0.0717\n",
      "Epoch [9/10], Step [50/164], Loss: 0.1170\n",
      "Epoch [9/10], Step [75/164], Loss: 0.1016\n",
      "Epoch [9/10], Step [100/164], Loss: 0.0800\n",
      "Epoch [9/10], Step [125/164], Loss: 0.0952\n",
      "Epoch [9/10], Step [150/164], Loss: 0.0845\n",
      "\n",
      "- FOLD:4 VALIDATION #9 START -\n",
      "\n",
      "VALIDATION #9  Average Loss: 0.2732, mIoU: 0.4892, acc : 0.9291\n",
      "\n",
      "- FOLD:4 VALIDATION #9 DONE - TIME:96.48783707618713\n",
      "\n",
      "Epoch [10/10], Step [25/164], Loss: 0.0811\n",
      "Epoch [10/10], Step [50/164], Loss: 0.0747\n",
      "Epoch [10/10], Step [75/164], Loss: 0.0634\n",
      "Epoch [10/10], Step [100/164], Loss: 0.1322\n",
      "Epoch [10/10], Step [125/164], Loss: 0.0978\n",
      "Epoch [10/10], Step [150/164], Loss: 0.1001\n",
      "\n",
      "- FOLD:4 VALIDATION #10 START -\n",
      "\n",
      "VALIDATION #10  Average Loss: 0.2770, mIoU: 0.4983, acc : 0.9299\n",
      "\n",
      "- FOLD:4 VALIDATION #10 DONE - TIME:93.43629097938538\n",
      "\n",
      "\n",
      "- Fold:4 Training DONE - TIME:6244.696000814438\n",
      "\n",
      "###### Fold:5 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=4.76s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.91s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:5 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:5 Training Start - \n",
      "\n",
      "Epoch [1/10], Step [25/164], Loss: 1.4387\n",
      "Epoch [1/10], Step [50/164], Loss: 1.0381\n",
      "Epoch [1/10], Step [75/164], Loss: 0.8085\n",
      "Epoch [1/10], Step [100/164], Loss: 0.7388\n",
      "Epoch [1/10], Step [125/164], Loss: 0.6397\n",
      "Epoch [1/10], Step [150/164], Loss: 0.5670\n",
      "\n",
      "- FOLD:5 VALIDATION #1 START -\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.6638, mIoU: 0.2811, acc : 0.8367\n",
      "\n",
      "- FOLD:5 VALIDATION #1 DONE - TIME:97.09389972686768\n",
      "\n",
      "[loss] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [2/10], Step [25/164], Loss: 0.4443\n",
      "Epoch [2/10], Step [50/164], Loss: 0.3846\n",
      "Epoch [2/10], Step [75/164], Loss: 0.4296\n",
      "Epoch [2/10], Step [100/164], Loss: 0.5213\n",
      "Epoch [2/10], Step [125/164], Loss: 0.4996\n",
      "Epoch [2/10], Step [150/164], Loss: 0.2809\n",
      "\n",
      "- FOLD:5 VALIDATION #2 START -\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.5364, mIoU: 0.3704, acc : 0.8565\n",
      "\n",
      "- FOLD:5 VALIDATION #2 DONE - TIME:94.19138145446777\n",
      "\n",
      "[loss] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [3/10], Step [25/164], Loss: 0.2307\n",
      "Epoch [3/10], Step [50/164], Loss: 0.2688\n",
      "Epoch [3/10], Step [75/164], Loss: 0.2361\n",
      "Epoch [3/10], Step [100/164], Loss: 0.2265\n",
      "Epoch [3/10], Step [125/164], Loss: 0.2239\n",
      "Epoch [3/10], Step [150/164], Loss: 0.2711\n",
      "\n",
      "- FOLD:5 VALIDATION #3 START -\n",
      "\n",
      "VALIDATION #3  Average Loss: 0.5414, mIoU: 0.3670, acc : 0.8572\n",
      "\n",
      "- FOLD:5 VALIDATION #3 DONE - TIME:95.60042309761047\n",
      "\n",
      "Epoch [4/10], Step [25/164], Loss: 0.1770\n",
      "Epoch [4/10], Step [50/164], Loss: 0.1683\n",
      "Epoch [4/10], Step [75/164], Loss: 0.2956\n",
      "Epoch [4/10], Step [100/164], Loss: 0.1555\n",
      "Epoch [4/10], Step [125/164], Loss: 0.1787\n",
      "Epoch [4/10], Step [150/164], Loss: 0.1885\n",
      "\n",
      "- FOLD:5 VALIDATION #4 START -\n",
      "\n",
      "VALIDATION #4  Average Loss: 0.5328, mIoU: 0.3845, acc : 0.8639\n",
      "\n",
      "- FOLD:5 VALIDATION #4 DONE - TIME:94.87494683265686\n",
      "\n",
      "[loss] Best performance at epoch: 4\n",
      "Save model in /opt/ml/code/saved/skf\n",
      "Epoch [5/10], Step [25/164], Loss: 0.1223\n",
      "Epoch [5/10], Step [50/164], Loss: 0.1818\n",
      "Epoch [5/10], Step [75/164], Loss: 0.1752\n",
      "Epoch [5/10], Step [100/164], Loss: 0.2143\n",
      "Epoch [5/10], Step [125/164], Loss: 0.1444\n",
      "Epoch [5/10], Step [150/164], Loss: 0.1262\n",
      "\n",
      "- FOLD:5 VALIDATION #5 START -\n",
      "\n",
      "VALIDATION #5  Average Loss: 0.5483, mIoU: 0.3913, acc : 0.8645\n",
      "\n",
      "- FOLD:5 VALIDATION #5 DONE - TIME:95.49419116973877\n",
      "\n",
      "Epoch [6/10], Step [25/164], Loss: 0.1461\n",
      "Epoch [6/10], Step [50/164], Loss: 0.1083\n",
      "Epoch [6/10], Step [75/164], Loss: 0.1918\n",
      "Epoch [6/10], Step [100/164], Loss: 0.0986\n",
      "Epoch [6/10], Step [125/164], Loss: 0.1387\n",
      "Epoch [6/10], Step [150/164], Loss: 0.1788\n",
      "\n",
      "- FOLD:5 VALIDATION #6 START -\n",
      "\n",
      "VALIDATION #6  Average Loss: 0.5562, mIoU: 0.3879, acc : 0.8649\n",
      "\n",
      "- FOLD:5 VALIDATION #6 DONE - TIME:97.59523463249207\n",
      "\n",
      "Epoch [7/10], Step [25/164], Loss: 0.0841\n",
      "Epoch [7/10], Step [50/164], Loss: 0.0855\n",
      "Epoch [7/10], Step [75/164], Loss: 0.1160\n",
      "Epoch [7/10], Step [100/164], Loss: 0.0836\n",
      "Epoch [7/10], Step [125/164], Loss: 0.1172\n",
      "Epoch [7/10], Step [150/164], Loss: 0.1004\n",
      "\n",
      "- FOLD:5 VALIDATION #7 START -\n",
      "\n",
      "VALIDATION #7  Average Loss: 0.5791, mIoU: 0.3906, acc : 0.8653\n",
      "\n",
      "- FOLD:5 VALIDATION #7 DONE - TIME:98.25421118736267\n",
      "\n",
      "Epoch [8/10], Step [25/164], Loss: 0.0702\n",
      "Epoch [8/10], Step [50/164], Loss: 0.0782\n",
      "Epoch [8/10], Step [75/164], Loss: 0.0889\n",
      "Epoch [8/10], Step [100/164], Loss: 0.1331\n",
      "Epoch [8/10], Step [125/164], Loss: 0.1015\n",
      "Epoch [8/10], Step [150/164], Loss: 0.1217\n",
      "\n",
      "- FOLD:5 VALIDATION #8 START -\n",
      "\n",
      "VALIDATION #8  Average Loss: 0.5906, mIoU: 0.3954, acc : 0.8659\n",
      "\n",
      "- FOLD:5 VALIDATION #8 DONE - TIME:95.06956648826599\n",
      "\n",
      "Epoch [9/10], Step [25/164], Loss: 0.0990\n",
      "Epoch [9/10], Step [50/164], Loss: 0.0827\n",
      "Epoch [9/10], Step [75/164], Loss: 0.0989\n",
      "Epoch [9/10], Step [100/164], Loss: 0.0630\n",
      "Epoch [9/10], Step [125/164], Loss: 0.1097\n",
      "Epoch [9/10], Step [150/164], Loss: 0.1326\n",
      "\n",
      "- FOLD:5 VALIDATION #9 START -\n",
      "\n",
      "VALIDATION #9  Average Loss: 0.6124, mIoU: 0.3875, acc : 0.8667\n",
      "\n",
      "- FOLD:5 VALIDATION #9 DONE - TIME:94.86963510513306\n",
      "\n",
      "Epoch [10/10], Step [25/164], Loss: 0.0773\n",
      "Epoch [10/10], Step [50/164], Loss: 0.0891\n",
      "Epoch [10/10], Step [75/164], Loss: 0.0868\n",
      "Epoch [10/10], Step [100/164], Loss: 0.0762\n",
      "Epoch [10/10], Step [125/164], Loss: 0.0929\n",
      "Epoch [10/10], Step [150/164], Loss: 0.0909\n",
      "\n",
      "- FOLD:5 VALIDATION #10 START -\n",
      "\n",
      "VALIDATION #10  Average Loss: 0.6038, mIoU: 0.4439, acc : 0.8719\n",
      "\n",
      "- FOLD:5 VALIDATION #10 DONE - TIME:96.98534965515137\n",
      "\n",
      "\n",
      "- Fold:5 Training DONE - TIME:6227.782730817795\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/opt/ml/input/data/train_all.json'\n",
    "alldata = pd.read_csv('/opt/ml/code/alldata.csv')\n",
    "\n",
    "SKF(alldata,data_dir,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(folder_path):\n",
    "\n",
    "    from glob import glob\n",
    "    from scipy import stats\n",
    "\n",
    "    model_list = glob(folder_path + '/*')\n",
    "    test = pd.read_csv('/opt/ml/code/testdata.csv')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    size = 256\n",
    "\n",
    "    n_folds = len(model_list)\n",
    "\n",
    "    soft_voting = [] # Fold,Data,12,256,256\n",
    "    hard_voting = [] # Fold,Data,256,256\n",
    "    \n",
    "\n",
    "    for fold in range(n_folds):\n",
    "\n",
    "        print(f'\\n@@@@@@@@@ FOLD {fold+1} INFERENCE START @@@@@@@@@ - TIME:0\\n')\n",
    "        start_time = time.time()\n",
    "        \n",
    "        file_name_list = []\n",
    "        preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "        one_soft = [] # Data,12,256,256\n",
    "\n",
    "        print(f'\\n- FOLD {fold+1} DATASET LOAD START -\\n')\n",
    "        test_dataloader = get_test_dataloader(test)\n",
    "        model = torch.load(model_list[fold])\n",
    "        model.eval()\n",
    "        print(f'\\n- FOLD {fold+1} DATASET LOAD DONE -\\n')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (imgs, image_infos) in enumerate(test_dataloader):\n",
    "                \n",
    "                if (step+1)%5==0 or step+1==len(test_dataloader):\n",
    "                    print(f'STEP [{step+1}/{len(test_dataloader)}]')\n",
    "                \n",
    "                # inference (512 x 512)\n",
    "                outs = model(torch.stack(imgs).to(device)) # batch, 12, 512, 512\n",
    "\n",
    "                ######### soft voting #########\n",
    "                soft = outs.detach().cpu().numpy()\n",
    "                soft = soft.transpose(0,2,3,1)\n",
    "                \n",
    "                channel_list = []\n",
    "                for image in soft:\n",
    "                    transformed_mask = test_transform(image=image)['image']\n",
    "                    channel_list.append(transformed_mask)\n",
    "\n",
    "                # (batch, 12, 256, 256)\n",
    "                soft = torch.stack(channel_list)\n",
    "                soft = soft.numpy()\n",
    "                \n",
    "                one_soft.append(soft)\n",
    "                ################################\n",
    "\n",
    "                ######### hard voting #########\n",
    "                oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "                \n",
    "                # resize (256 x 256)\n",
    "                temp_mask = []\n",
    "                for img, mask in zip(np.stack(imgs), oms):\n",
    "                    transformed = A.Compose([A.Resize(size, size)])(image=img, mask=mask)\n",
    "                    mask = transformed['mask']\n",
    "                    temp_mask.append(mask)\n",
    "\n",
    "                oms = np.array(temp_mask)\n",
    "                \n",
    "                oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "                preds_array = np.vstack((preds_array, oms))\n",
    "\n",
    "                file_name_list.append([i for i in image_infos])\n",
    "                \n",
    "        # soft voting\n",
    "        one_soft = np.array(one_soft)\n",
    "        one_soft = np.concatenate(one_soft)\n",
    "        soft_voting.append(one_soft)\n",
    "        print(f'soft voting size: {one_soft.shape}')\n",
    "\n",
    "        # hard voting\n",
    "        hard_voting.append(preds_array)\n",
    "        print(f'hard voting size: {preds_array.shape}')\n",
    "        print(f'\\n@@@@@@@@@ FOLD {fold+1} INFERENCE DONE @@@@@@@@@ - TIME:{time.time()-start_time}\\n')\n",
    "        \n",
    "        # file names\n",
    "        if fold == 1:\n",
    "            file_names = [y for x in file_name_list for y in x]\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return file_names, soft_voting, hard_voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@@@@@@@@@ FOLD 1 INFERENCE START @@@@@@@@@ - TIME:0\n",
      "\n",
      "\n",
      "- FOLD 1 DATASET LOAD START -\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "- FOLD 1 DATASET LOAD DONE -\n",
      "\n",
      "STEP [5/53]\n",
      "STEP [10/53]\n",
      "STEP [15/53]\n",
      "STEP [20/53]\n",
      "STEP [25/53]\n",
      "STEP [30/53]\n",
      "STEP [35/53]\n",
      "STEP [40/53]\n",
      "STEP [45/53]\n",
      "STEP [50/53]\n",
      "STEP [53/53]\n",
      "soft voting size: (837, 12, 256, 256)\n",
      "hard voting size: (837, 65536)\n",
      "\n",
      "@@@@@@@@@ FOLD 1 INFERENCE DONE @@@@@@@@@ - TIME:580.6958570480347\n",
      "\n",
      "\n",
      "@@@@@@@@@ FOLD 2 INFERENCE START @@@@@@@@@ - TIME:0\n",
      "\n",
      "\n",
      "- FOLD 2 DATASET LOAD START -\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "- FOLD 2 DATASET LOAD DONE -\n",
      "\n",
      "STEP [5/53]\n",
      "STEP [10/53]\n",
      "STEP [15/53]\n",
      "STEP [20/53]\n",
      "STEP [25/53]\n",
      "STEP [30/53]\n",
      "STEP [35/53]\n",
      "STEP [40/53]\n",
      "STEP [45/53]\n",
      "STEP [50/53]\n",
      "STEP [53/53]\n",
      "soft voting size: (837, 12, 256, 256)\n",
      "hard voting size: (837, 65536)\n",
      "\n",
      "@@@@@@@@@ FOLD 2 INFERENCE DONE @@@@@@@@@ - TIME:579.6705276966095\n",
      "\n",
      "\n",
      "@@@@@@@@@ FOLD 3 INFERENCE START @@@@@@@@@ - TIME:0\n",
      "\n",
      "\n",
      "- FOLD 3 DATASET LOAD START -\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "- FOLD 3 DATASET LOAD DONE -\n",
      "\n",
      "STEP [5/53]\n",
      "STEP [10/53]\n",
      "STEP [15/53]\n",
      "STEP [20/53]\n",
      "STEP [25/53]\n",
      "STEP [30/53]\n",
      "STEP [35/53]\n",
      "STEP [40/53]\n",
      "STEP [45/53]\n",
      "STEP [50/53]\n",
      "STEP [53/53]\n",
      "soft voting size: (837, 12, 256, 256)\n",
      "hard voting size: (837, 65536)\n",
      "\n",
      "@@@@@@@@@ FOLD 3 INFERENCE DONE @@@@@@@@@ - TIME:638.7033607959747\n",
      "\n",
      "\n",
      "@@@@@@@@@ FOLD 4 INFERENCE START @@@@@@@@@ - TIME:0\n",
      "\n",
      "\n",
      "- FOLD 4 DATASET LOAD START -\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "- FOLD 4 DATASET LOAD DONE -\n",
      "\n",
      "STEP [5/53]\n",
      "STEP [10/53]\n",
      "STEP [15/53]\n",
      "STEP [20/53]\n",
      "STEP [25/53]\n",
      "STEP [30/53]\n",
      "STEP [35/53]\n",
      "STEP [40/53]\n",
      "STEP [45/53]\n",
      "STEP [50/53]\n",
      "STEP [53/53]\n",
      "soft voting size: (837, 12, 256, 256)\n",
      "hard voting size: (837, 65536)\n",
      "\n",
      "@@@@@@@@@ FOLD 4 INFERENCE DONE @@@@@@@@@ - TIME:637.5473010540009\n",
      "\n",
      "\n",
      "@@@@@@@@@ FOLD 5 INFERENCE START @@@@@@@@@ - TIME:0\n",
      "\n",
      "\n",
      "- FOLD 5 DATASET LOAD START -\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "- FOLD 5 DATASET LOAD DONE -\n",
      "\n",
      "STEP [5/53]\n",
      "STEP [10/53]\n",
      "STEP [15/53]\n",
      "STEP [20/53]\n",
      "STEP [25/53]\n",
      "STEP [30/53]\n",
      "STEP [35/53]\n",
      "STEP [40/53]\n",
      "STEP [45/53]\n",
      "STEP [50/53]\n",
      "STEP [53/53]\n",
      "soft voting size: (837, 12, 256, 256)\n",
      "hard voting size: (837, 65536)\n",
      "\n",
      "@@@@@@@@@ FOLD 5 INFERENCE DONE @@@@@@@@@ - TIME:639.6639416217804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test set에 대한 prediction\n",
    "folder_path = '/opt/ml/code/saved/single'\n",
    "encoder_name = \"se_resnet101\"\n",
    "file_names, soft_voting, hard_voting = inference(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_process(soft_voting,hard_voting,size):\n",
    "    print(f'\\n---------- ENSEMBLING START ---------- TIME:0')\n",
    "    start_time = time.time()\n",
    "    soft_voting = np.array(soft_voting) # Fold,Data,12,256,256\n",
    "    soft_voting = np.sum(soft_voting, axis=0) # Data,12,256,256\n",
    "    soft_voting = np.argmax(soft_voting, axis=1) # Data,256,256\n",
    "    soft_voting = soft_voting.reshape([soft_voting.shape[0], size*size]).astype(int)# Data,256*256\n",
    "    \n",
    "    hard_voting = np.array(hard_voting) # Fold,Data,256*256\n",
    "    hard_voting = stats.mode(hard_voting)[0] # Data,256*256\n",
    "    hard_voting = np.squeeze(hard_voting)\n",
    "    print(f'\\n---------- ENSEMBLING DONE ---------- TIME:{time.time()-start_time}')\n",
    "    return soft_voting, hard_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- ENSEMBLING START ---------- TIME:0\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 12.3 GiB for an array with shape (5, 837, 12, 256, 256) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7b4373d8aa25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msoft_voting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard_voting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoft_voting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard_voting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-022162996d10>\u001b[0m in \u001b[0;36mensemble_process\u001b[0;34m(soft_voting, hard_voting, size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n---------- ENSEMBLING START ---------- TIME:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msoft_voting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoft_voting\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Fold,Data,12,256,256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msoft_voting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoft_voting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Data,12,256,256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msoft_voting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoft_voting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Data,256,256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 12.3 GiB for an array with shape (5, 837, 12, 256, 256) and data type float32"
     ]
    }
   ],
   "source": [
    "size = 256\n",
    "soft_voting, hard_voting = ensemble_process(soft_voting, hard_voting, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "for file_name, string in tqdm(zip(file_names, soft_voting)):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "submission.to_csv(f\"/opt/ml/code/submission/{encoder_name}(pretrained)_soft_voting.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softdata = pd.read_csv(f\"/opt/ml/code/submission/{encoder_name}(pretrained)_soft_voting.csv\")\n",
    "softdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "    \n",
    "for file_name, string in tqdm(zip(file_names, hard_voting)):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "submission.to_csv(f\"/opt/ml/code/submission/{encoder_name}(pretrained)_hard_voting.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harddata = pd.read_csv(f\"/opt/ml/code/submission/{encoder_name}(pretrained)_hard_voting.csv\")\n",
    "harddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.278px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
