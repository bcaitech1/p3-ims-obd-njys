{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:58.944902Z",
     "start_time": "2021-04-22T11:06:56.623974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.7.1\n",
      "GPU 사용 가능 여부: True\n",
      "Tesla P40\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import *\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamters And Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.171980Z",
     "start_time": "2021-04-22T11:06:59.167952Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16   # Mini-batch size\n",
    "num_epochs = 35\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.446510Z",
     "start_time": "2021-04-22T11:06:59.443508Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 batch_size = 32,\n",
    "                 num_epochs = 20,\n",
    "                 learning_rate = 0.0001,\n",
    "                 seed = 21,\n",
    "                 val_every = 1,\n",
    "                 num_workers = 4,\n",
    "                 cutmix = False,\n",
    "                 half = False,\n",
    "                 train_resize = 224,\n",
    "                 test_resize = 256,\n",
    "                 encoder_name = 'senet154',\n",
    "                 encoder_weights = \"imagenet\",\n",
    "                 n_folds = 0, \n",
    "                 gkf = False, \n",
    "                 skf = False):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.seed = seed\n",
    "        self.val_every = val_every\n",
    "        self.num_workers = num_workers\n",
    "        self.cutmix = cutmix\n",
    "        self.half = half\n",
    "        self.train_resize = train_resize\n",
    "        self.test_resize = test_resize\n",
    "        self.encoder_name = encoder_name\n",
    "        self.encoder_weights = encoder_weights\n",
    "        self.n_folds = n_folds\n",
    "        self.gkf = gkf\n",
    "        self.skf = skf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://app.wandb.ai/authorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# wandb.init(project=\"P STAGE 3\",\n",
    "#            config={\n",
    "#                \"batch_size\": 32,\n",
    "#                \"learning_rate\": 0.0001,\n",
    "#                \"dataset\": \"COCO Trash\",\n",
    "#            })\n",
    "\n",
    "# # wandb.log({\n",
    "# #     'acc':,\n",
    "# #     'loss':,\n",
    "# # })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam, half=False)->tuple:\n",
    "    '''\n",
    "    랜덤한 bounding box의 좌상단,우하단 좌표 반환\n",
    "\n",
    "    Args:\n",
    "        size (tuple): batch의 shape\n",
    "        lam (float): 자를 비율\n",
    "        half (bool): 절반으로 자름\n",
    "    '''\n",
    "\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    \n",
    "    if half==False:\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W) \n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    else:\n",
    "        bbx1 = 0\n",
    "        bby1 = 0\n",
    "        bbx2 = W//2\n",
    "        bby2 = H\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(image, mask, alpha, half=False):\n",
    "    '''\n",
    "    이미지와 마스크 컷믹스\n",
    "\n",
    "    Args:\n",
    "        image (tensor): batch 이미지\n",
    "        mask (tensor): batch 마스크\n",
    "        alpha (float): Beta Distribution의 alpha 값\n",
    "    '''\n",
    "  \n",
    "    indices = torch.randperm(image.size(0)) # 배치 크기 입력\n",
    "\n",
    "    lam = np.clip(np.random.beta(alpha, alpha),0.3,0.4)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(image.size(), lam, half)\n",
    "    new_image = image.clone()\n",
    "    new_mask = mask.clone()\n",
    "    new_image[:, :, bby1:bby2, bbx1:bbx2] = image[indices, :, bby1:bby2, bbx1:bbx2]\n",
    "    new_mask[:, bby1:bby2, bbx1:bbx2] = mask[indices, bby1:bby2, bbx1:bbx2]\n",
    "\n",
    "    return new_image, new_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, Rotate, CropNonEmptyMaskIfExists,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "train_transform = Compose([\n",
    "                            CropNonEmptyMaskIfExists(width = 400, height = 400),\n",
    "                            CLAHE(clip_limit=2),\n",
    "                            HorizontalFlip(),\n",
    "                            GridDistortion(),\n",
    "                            ShiftScaleRotate(),\n",
    "                            Resize(512, 512),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = Compose([\n",
    "                        ToTensorV2()\n",
    "                        ])\n",
    "\n",
    "test_transform = Compose([\n",
    "                          ToTensorV2()\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>num_objects</th>\n",
       "      <th>bin</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>General trash</th>\n",
       "      <th>Paper</th>\n",
       "      <th>Paper pack</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Glass</th>\n",
       "      <th>Plastic</th>\n",
       "      <th>Styrofoam</th>\n",
       "      <th>Plastic bag</th>\n",
       "      <th>Battery</th>\n",
       "      <th>Clothing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0002.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0003.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0005.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0006.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0007.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>3267</td>\n",
       "      <td>/opt/ml/input/data/batch_03/0994.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>3268</td>\n",
       "      <td>/opt/ml/input/data/batch_03/0995.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>3269</td>\n",
       "      <td>/opt/ml/input/data/batch_03/0996.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>3270</td>\n",
       "      <td>/opt/ml/input/data/batch_03/0997.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>3271</td>\n",
       "      <td>/opt/ml/input/data/batch_03/1000.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3272 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                     path  width  height  \\\n",
       "0            0  /opt/ml/input/data/batch_01_vt/0002.jpg    512     512   \n",
       "1            1  /opt/ml/input/data/batch_01_vt/0003.jpg    512     512   \n",
       "2            2  /opt/ml/input/data/batch_01_vt/0005.jpg    512     512   \n",
       "3            3  /opt/ml/input/data/batch_01_vt/0006.jpg    512     512   \n",
       "4            4  /opt/ml/input/data/batch_01_vt/0007.jpg    512     512   \n",
       "...        ...                                      ...    ...     ...   \n",
       "3267      3267     /opt/ml/input/data/batch_03/0994.jpg    512     512   \n",
       "3268      3268     /opt/ml/input/data/batch_03/0995.jpg    512     512   \n",
       "3269      3269     /opt/ml/input/data/batch_03/0996.jpg    512     512   \n",
       "3270      3270     /opt/ml/input/data/batch_03/0997.jpg    512     512   \n",
       "3271      3271     /opt/ml/input/data/batch_03/1000.jpg    512     512   \n",
       "\n",
       "      num_objects  bin  UNKNOWN  General trash  Paper  Paper pack  Metal  \\\n",
       "0              17    4        0              0      0           0      0   \n",
       "1              14    4        0              8      0           0      0   \n",
       "2               1    1        0              0      0           0      0   \n",
       "3               2    2        0              0      0           0      1   \n",
       "4               2    2        0              0      0           0      0   \n",
       "...           ...  ...      ...            ...    ...         ...    ...   \n",
       "3267            7    3        0              0      2           0      0   \n",
       "3268           14    4        0              0     12           0      1   \n",
       "3269            4    2        0              2      1           0      0   \n",
       "3270            8    3        0              0      8           0      0   \n",
       "3271            1    1        0              0      0           0      1   \n",
       "\n",
       "      Glass  Plastic  Styrofoam  Plastic bag  Battery  Clothing  \n",
       "0         4        4          0            9        0         0  \n",
       "1         0        0          0            6        0         0  \n",
       "2         0        1          0            0        0         0  \n",
       "3         0        1          0            0        0         0  \n",
       "4         0        2          0            0        0         0  \n",
       "...     ...      ...        ...          ...      ...       ...  \n",
       "3267      0        2          2            1        0         0  \n",
       "3268      0        0          0            1        0         0  \n",
       "3269      0        0          1            0        0         0  \n",
       "3270      0        0          0            0        0         0  \n",
       "3271      0        0          0            0        0         0  \n",
       "\n",
       "[3272 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0021.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0028.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0031.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0032.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/opt/ml/input/data/batch_01_vt/0070.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>832</td>\n",
       "      <td>/opt/ml/input/data/batch_03/0947.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>833</td>\n",
       "      <td>/opt/ml/input/data/batch_03/0968.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>834</td>\n",
       "      <td>/opt/ml/input/data/batch_03/0969.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>/opt/ml/input/data/batch_03/0992.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>836</td>\n",
       "      <td>/opt/ml/input/data/batch_03/0998.jpg</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id                                     path  width  height\n",
       "0           0  /opt/ml/input/data/batch_01_vt/0021.jpg    256     256\n",
       "1           1  /opt/ml/input/data/batch_01_vt/0028.jpg    256     256\n",
       "2           2  /opt/ml/input/data/batch_01_vt/0031.jpg    256     256\n",
       "3           3  /opt/ml/input/data/batch_01_vt/0032.jpg    256     256\n",
       "4           4  /opt/ml/input/data/batch_01_vt/0070.jpg    256     256\n",
       "..        ...                                      ...    ...     ...\n",
       "832       832     /opt/ml/input/data/batch_03/0947.jpg    256     256\n",
       "833       833     /opt/ml/input/data/batch_03/0968.jpg    256     256\n",
       "834       834     /opt/ml/input/data/batch_03/0969.jpg    256     256\n",
       "835       835     /opt/ml/input/data/batch_03/0992.jpg    256     256\n",
       "836       836     /opt/ml/input/data/batch_03/0998.jpg    256     256\n",
       "\n",
       "[837 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alldata=pd.read_csv('/opt/ml/code/alldata.csv')\n",
    "testdata=pd.read_csv('/opt/ml/code/testdata.csv')\n",
    "display(alldata,testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['Backgroud','UNKNOWN','General trash','Paper','Paper pack','Metal',\n",
    "                    'Glass','Plastic','Styrofoam','Plastic bag','Battery','Clothing']\n",
    "data_dir = '/opt/ml/input/data/train_all.json'\n",
    "\n",
    "class TrashDataset(Dataset):\n",
    "    \"\"\"DataFrame format\"\"\"\n",
    "    def __init__(self, dataframe, data_dir, mode = 'Train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        image_id = self.df.iloc[index]['image_id']\n",
    "        path = self.df.iloc[index]['path']\n",
    "        width = self.df.iloc[index]['width']\n",
    "        height = self.df.iloc[index]['height']      \n",
    "        images = cv2.imread(path)\n",
    "        # images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32) # np.float32 -> np.uint8\n",
    "        # images /= 255.0\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.uint8)\n",
    "        \n",
    "        \n",
    "        if self.mode == 'Train':\n",
    "            bin = self.df.iloc[index]['bin']\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_id)\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            masks = np.zeros((height,width))\n",
    "            # Background = 0, Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for ann in anns:\n",
    "                pixel_value = ann['category_id']+1\n",
    "                masks = np.maximum(self.coco.annToMask(ann)*pixel_value, masks)\n",
    "            # masks = masks.astype(np.float32) # np.float32 -> np.uint8\n",
    "            masks = masks.astype(np.uint8)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return images, masks, bin\n",
    "        \n",
    "        if self.mode == 'Test':\n",
    "            file_name = path.split('/')[-2:]\n",
    "            file_name = \"/\".join(file_name)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return images, file_name\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Fold를 위한 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_dataloader(df, trn_idx, val_idx,fold):\n",
    "\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    data_dir = '/opt/ml/input/data/train_all.json'\n",
    "    \n",
    "    # 학습, 벨리데이션 데이터프레임 생성\n",
    "    train_df = df.iloc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_df = df.iloc[val_idx,:].reset_index(drop=True)\n",
    "    \n",
    "    # 학습, 벨리데이션 데이터셋 생성\n",
    "    print(f'\\n###### Fold:{fold} - Loading Dataset ######\\n')\n",
    "    train_ds = TrashDataset(train_df, data_dir=data_dir, transform=train_transform, mode='Train')\n",
    "    valid_ds = TrashDataset(valid_df, data_dir=data_dir, transform=val_transform, mode='Train')\n",
    "    print(f'\\n###### Fold:{fold} - Loading Dataset - DONE ######\\n')\n",
    "    \n",
    "    # 학습, 벨리데이션 데이터로더 생성\n",
    "    train_dataloader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        shuffle=True,        \n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    return train_dataloader, val_dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test를 위한 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataloader(df):\n",
    "    data_dir = '/opt/ml/input/data/test.json'\n",
    "    test_ds = TrashDataset(df,data_dir,'Test',test_transform)\n",
    "\n",
    "    tst_dataloader = torch.utils.data.DataLoader(\n",
    "                                                test_ds, \n",
    "                                                batch_size=batch_size,\n",
    "                                                num_workers=4,\n",
    "                                                shuffle=False,\n",
    "                                                pin_memory=False,\n",
    "                                                collate_fn=collate_fn,\n",
    "                                                )\n",
    "    \n",
    "    return tst_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeepLabV3',\n",
       " 'DeepLabV3Plus',\n",
       " 'FPN',\n",
       " 'Linknet',\n",
       " 'PAN',\n",
       " 'PSPNet',\n",
       " 'Unet',\n",
       " 'UnetPlusPlus',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'base',\n",
       " 'deeplabv3',\n",
       " 'encoders',\n",
       " 'fpn',\n",
       " 'linknet',\n",
       " 'pan',\n",
       " 'pspnet',\n",
       " 'unet',\n",
       " 'unetplusplus',\n",
       " 'utils']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from pprint import pprint\n",
    "dir(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(encoder_name,encoder_weights,in_channels=3,classes=12):\n",
    "    model = smp.DeepLabV3Plus(\n",
    "    encoder_name=encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=encoder_weights,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=in_channels,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=classes,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = \"se_resnext101_32x4d\"\n",
    "encoder_weights = \"imagenet\"\n",
    "model = get_model(encoder_name,encoder_weights)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "preprocess_input = get_preprocessing_fn(encoder_name, pretrained=encoder_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:34.624277Z",
     "start_time": "2021-04-22T11:15:30.068347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape :  torch.Size([1, 3, 512, 512])\n",
      "output shape :  torch.Size([1, 12, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n",
    "\n",
    "#model = FCN8s(model = model, num_classes=12)\n",
    "x = torch.randn([1, 3, 512, 512])\n",
    "print(\"input shape : \", x.shape)\n",
    "out = model(x).to(device)\n",
    "print(\"output shape : \", out.size())\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train And Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:38.901226Z",
     "start_time": "2021-04-22T11:15:38.888195Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(fold, epoch, model, valid_dataloader, criterion, device):\n",
    "    print(f'\\n- FOLD:{fold} VALIDATION #{epoch} START - TIME:0\\n')\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    hist = np.zeros((12, 12))\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        for step, (images, masks, _) in enumerate(valid_dataloader):\n",
    "            \n",
    "            # images = torch.stack(images).to(device)       # (batch, channel, height, width)\n",
    "            images = torch.stack(images).float().to(device)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long().to(device)  # (batch, channel, height, width)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            \n",
    "            outputs = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            hist = add_hist(hist, masks.detach().cpu().numpy(), outputs, n_class=12)\n",
    "            \n",
    "        acc, acc_cls, mIoU, fwavacc = label_accuracy_score(hist)    \n",
    "        avrg_loss = total_loss / cnt\n",
    "        print(f'VALIDATION #{epoch}  Average Loss: {avrg_loss:.4f}, mIoU: {mIoU:.4f}, acc : {acc:.4f}')\n",
    "    print(f'\\n- FOLD:{fold} VALIDATION #{epoch} DONE - TIME:{time.time()-start_time}\\n')\n",
    "    return avrg_loss, mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:38.201874Z",
     "start_time": "2021-04-22T11:15:38.187884Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(fold, num_epochs, model, train_dataloader, valid_dataloader, criterion, optimizer, saved_dir, val_every, device, encoder_name):\n",
    "    print(f'- Fold:{fold} Training Start - TIME:0\\n')\n",
    "    start_time = time.time()\n",
    "    best_loss = 9999999\n",
    "    best_mIoU = 0\n",
    "    \n",
    "    # GradScaler 선언\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        print(f'- Fold:{fold} Epoch:{epoch+1} Training Start - TIME:0\\n')\n",
    "        epoch_start=time.time()\n",
    "        for step, (images, masks, bin) in enumerate(train_dataloader):\n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "            \n",
    "            # gpu 연산을 위해 device 할당\n",
    "            # images, masks = images.to(device), masks.to(device) # uint8 -> float32\n",
    "            images, masks = images.float().to(device), masks.to(device)\n",
    "\n",
    "#             #####################################\n",
    "#             # 50% 확률로 CutMix\n",
    "#             mix_decision = np.random.rand()\n",
    "#             if mix_decision < 0.5:\n",
    "#                 # cutmix(data, target, alpha)\n",
    "#                 images, masks = cutmix(images, masks, 1.)\n",
    "#             #####################################\n",
    "                  \n",
    "    \n",
    "            # zero_grad\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            ######################################## \n",
    "            # amp 실행\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # inference\n",
    "                outputs = model(images).to(device)\n",
    "\n",
    "                # loss 계산 (cross entropy loss)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer).step()\n",
    "            scaler.update()\n",
    "            \n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            ######################################## \n",
    "            \n",
    "            \n",
    "            \n",
    "            # step 주기에 따른 loss 출력\n",
    "            if (step + 1) % 25 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs, step+1, len(train_dataloader), loss.item()))\n",
    "        \n",
    "        # validation 주기에 따른 loss 출력 및 best model 저장\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss, mIoU = validation(fold, epoch + 1, model, valid_dataloader, criterion, device)\n",
    "#             if avrg_loss < best_loss:\n",
    "#                 print('[loss] Best performance at epoch: {}'.format(epoch + 1))\n",
    "#                 print('Save model in', saved_dir)\n",
    "#                 print()\n",
    "#                 best_loss = avrg_loss\n",
    "#                 save_model(model, saved_dir, file_name = f'fold[{fold}]_loss_best_{encoder_name}(pretrained).pt')\n",
    "            if mIoU > best_mIoU:\n",
    "                print('[mIoU] Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                print()\n",
    "                best_mIoU = mIoU\n",
    "                save_model(model, saved_dir, file_name = f'fold[{fold}]_mIoU_best_{encoder_name}(pretrained).pt')\n",
    "        print(f'- Fold:{fold} Epoch:{epoch+1} Training DONE - TIME:{time.time()-epoch_start}\\n')\n",
    "    print(f'\\n- Fold:{fold} Training DONE - TIME:{time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:41.634492Z",
     "start_time": "2021-04-22T11:15:41.627493Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 저장 함수 정의\n",
    "val_every = 1 \n",
    "    \n",
    "def save_model(model, saved_dir, file_name='fcn8s_best_model(pretrained).pt'):\n",
    "\n",
    "    import os\n",
    "\n",
    "    os.makedirs(saved_dir, exist_ok=True)\n",
    "\n",
    "    # 모델 자체를 저장\n",
    "    torch.save(model, saved_dir + '/'+ file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단일 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SingleModelTrain(df = pd.read_csv('/opt/ml/code/alldata.csv')):\n",
    "    \n",
    "    from pytorch_toolbelt import losses as L\n",
    "    \n",
    "    encoder_name = \"se_resnext101_32x4d\"\n",
    "    encoder_weights = \"imagenet\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    saved_dir = '/opt/ml/code/saved/single'\n",
    "    \n",
    "    ####### validation 크기 조절 #######\n",
    "    train_size = int(len(df)*0.8) # 80% & 20%\n",
    "    indices = np.random.permutation(len(df))\n",
    "    trn_idx = indices[:train_size]\n",
    "    val_idx = indices[train_size:]\n",
    "    ##################################\n",
    "    \n",
    "    model = get_model(encoder_name,encoder_weights)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # loss\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = L.FocalLoss()\n",
    "    criterion = L.SoftCrossEntropyLoss(smooth_factor = 0.1)\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)\n",
    "    \n",
    "    train_dataloader, valid_dataloader = get_train_valid_dataloader(df, trn_idx, val_idx, 1)\n",
    "    \n",
    "    train(fold=1,\n",
    "          num_epochs=20, \n",
    "          model=model, \n",
    "          train_dataloader=train_dataloader, \n",
    "          valid_dataloader=valid_dataloader, \n",
    "          criterion=criterion, \n",
    "          optimizer=optimizer, \n",
    "          saved_dir=saved_dir, \n",
    "          val_every=val_every, \n",
    "          device=device, \n",
    "          encoder_name=encoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SingleModelTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group K Fold\n",
    "- by = bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GKF(dataframe=pd.read_csv('/opt/ml/code/alldata.csv'),data_dir='/opt/ml/input/data/train_all.json',n_splits=5):\n",
    "\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "    from pytorch_toolbelt import losses as L\n",
    "\n",
    "    encoder_name = \"se_resnext101_32x4d\"\n",
    "    encoder_weights = \"imagenet\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    saved_dir = '/opt/ml/code/saved/gkf'\n",
    "\n",
    "    # bin 기준 나누기\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    folds = gkf.split(dataframe.values, y=None, groups=dataframe['bin'].values)\n",
    "\n",
    "    for i, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # fold별 모델\n",
    "        model = get_model(encoder_name,encoder_weights)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 데이터 로더\n",
    "        train_dataloader, valid_dataloader = get_train_valid_dataloader(dataframe, trn_idx, val_idx,fold=i+1)\n",
    "\n",
    "        # loss\n",
    "        # criterion = nn.CrossEntropyLoss()\n",
    "        # criterion = L.FocalLoss()\n",
    "        criterion = L.SoftCrossEntropyLoss(smooth_factor = 0.1)   \n",
    "        \n",
    "        # optimizer\n",
    "        optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)\n",
    "\n",
    "        # 학습\n",
    "        train(fold=i+1,\n",
    "              num_epochs=20, \n",
    "              model=model, \n",
    "              train_dataloader=train_dataloader, \n",
    "              valid_dataloader=valid_dataloader, \n",
    "              criterion=criterion, \n",
    "              optimizer=optimizer, \n",
    "              saved_dir=saved_dir, \n",
    "              val_every=val_every, \n",
    "              device=device, \n",
    "              encoder_name=encoder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '/opt/ml/input/data/train_all.json'\n",
    "# alldata = pd.read_csv('/opt/ml/code/alldata.csv')\n",
    "\n",
    "# GKF(alldata,data_dir,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Label Stratified K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch_toolbelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLSKF(dataframe=pd.read_csv('/opt/ml/code/alldata.csv'),data_dir='/opt/ml/input/data/train_all.json',n_splits=5):\n",
    "\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    from pytorch_toolbelt import losses as L\n",
    "\n",
    "    encoder_name = \"se_resnext101_32x4d\"\n",
    "    encoder_weights = \"imagenet\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    saved_dir = '/opt/ml/code/saved/mlskf_aug'\n",
    "    multi_label = ['bin','UNKNOWN','General trash','Paper','Paper pack','Metal',\n",
    "                'Glass','Plastic','Styrofoam','Plastic bag','Battery','Clothing']\n",
    "\n",
    "    # multi label 기준 나누기\n",
    "    mlskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2021)\n",
    "    folds = mlskf.split(dataframe.values, y=dataframe[multi_label].values)\n",
    "\n",
    "    for i, (trn_idx, val_idx) in enumerate(folds):\n",
    "        \n",
    "        if i!=4: continue\n",
    "            \n",
    "        # fold별 모델\n",
    "        model = get_model(encoder_name,encoder_weights)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 데이터 로더\n",
    "        train_dataloader, valid_dataloader = get_train_valid_dataloader(dataframe, trn_idx, val_idx,fold=i+1)\n",
    "\n",
    "        # loss\n",
    "        # criterion = nn.CrossEntropyLoss()\n",
    "        # criterion = L.FocalLoss()\n",
    "        criterion = L.SoftCrossEntropyLoss(smooth_factor = 0.1) \n",
    "        \n",
    "        # optimizer\n",
    "        optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)\n",
    "\n",
    "        # 학습\n",
    "        train(fold=i+1,\n",
    "              num_epochs=20, \n",
    "              model=model, \n",
    "              train_dataloader=train_dataloader, \n",
    "              valid_dataloader=valid_dataloader, \n",
    "              criterion=criterion, \n",
    "              optimizer=optimizer, \n",
    "              saved_dir=saved_dir, \n",
    "              val_every=val_every, \n",
    "              device=device, \n",
    "              encoder_name=encoder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Fold:1 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=4.12s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.81s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:1 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:1 Training Start - TIME:0\n",
      "\n",
      "- Fold:1 Epoch:1 Training Start - TIME:0\n",
      "\n",
      "Epoch [1/20], Step [25/164], Loss: 1.4671\n",
      "Epoch [1/20], Step [50/164], Loss: 1.1669\n",
      "Epoch [1/20], Step [75/164], Loss: 1.1847\n",
      "Epoch [1/20], Step [100/164], Loss: 0.9252\n",
      "Epoch [1/20], Step [125/164], Loss: 0.9467\n",
      "Epoch [1/20], Step [150/164], Loss: 0.9224\n",
      "\n",
      "- FOLD:1 VALIDATION #1 START - TIME:0\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.8190, mIoU: 0.3931, acc : 0.8959\n",
      "\n",
      "- FOLD:1 VALIDATION #1 DONE - TIME:113.57429814338684\n",
      "\n",
      "[mIoU] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:1 Epoch:1 Training DONE - TIME:793.8039793968201\n",
      "\n",
      "- Fold:1 Epoch:2 Training Start - TIME:0\n",
      "\n",
      "Epoch [2/20], Step [25/164], Loss: 0.9250\n",
      "Epoch [2/20], Step [50/164], Loss: 0.8451\n",
      "Epoch [2/20], Step [75/164], Loss: 0.8259\n",
      "Epoch [2/20], Step [100/164], Loss: 0.8496\n",
      "Epoch [2/20], Step [125/164], Loss: 0.8993\n",
      "Epoch [2/20], Step [150/164], Loss: 0.9185\n",
      "\n",
      "- FOLD:1 VALIDATION #2 START - TIME:0\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.7550, mIoU: 0.4568, acc : 0.9120\n",
      "\n",
      "- FOLD:1 VALIDATION #2 DONE - TIME:110.44636583328247\n",
      "\n",
      "[mIoU] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:1 Epoch:2 Training DONE - TIME:791.1720721721649\n",
      "\n",
      "- Fold:1 Epoch:3 Training Start - TIME:0\n",
      "\n",
      "Epoch [3/20], Step [25/164], Loss: 0.8393\n",
      "Epoch [3/20], Step [50/164], Loss: 0.9270\n",
      "Epoch [3/20], Step [75/164], Loss: 0.7799\n",
      "Epoch [3/20], Step [100/164], Loss: 0.8256\n",
      "Epoch [3/20], Step [125/164], Loss: 0.7715\n",
      "Epoch [3/20], Step [150/164], Loss: 0.7620\n",
      "\n",
      "- FOLD:1 VALIDATION #3 START - TIME:0\n",
      "\n",
      "VALIDATION #3  Average Loss: 0.7437, mIoU: 0.4773, acc : 0.9177\n",
      "\n",
      "- FOLD:1 VALIDATION #3 DONE - TIME:111.69916605949402\n",
      "\n",
      "[mIoU] Best performance at epoch: 3\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:1 Epoch:3 Training DONE - TIME:790.2172563076019\n",
      "\n",
      "- Fold:1 Epoch:4 Training Start - TIME:0\n",
      "\n",
      "Epoch [4/20], Step [25/164], Loss: 0.6865\n",
      "Epoch [4/20], Step [50/164], Loss: 0.8643\n",
      "Epoch [4/20], Step [75/164], Loss: 0.6493\n",
      "Epoch [4/20], Step [100/164], Loss: 0.7013\n",
      "Epoch [4/20], Step [125/164], Loss: 1.0007\n",
      "Epoch [4/20], Step [150/164], Loss: 0.8199\n",
      "\n",
      "- FOLD:1 VALIDATION #4 START - TIME:0\n",
      "\n",
      "VALIDATION #4  Average Loss: 0.7322, mIoU: 0.4815, acc : 0.9207\n",
      "\n",
      "- FOLD:1 VALIDATION #4 DONE - TIME:108.13283705711365\n",
      "\n",
      "[mIoU] Best performance at epoch: 4\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:1 Epoch:4 Training DONE - TIME:782.9079794883728\n",
      "\n",
      "- Fold:1 Epoch:5 Training Start - TIME:0\n",
      "\n",
      "Epoch [5/20], Step [25/164], Loss: 0.7422\n",
      "Epoch [5/20], Step [50/164], Loss: 0.6427\n",
      "Epoch [5/20], Step [75/164], Loss: 0.6700\n",
      "Epoch [5/20], Step [100/164], Loss: 0.7173\n",
      "Epoch [5/20], Step [125/164], Loss: 0.7362\n",
      "Epoch [5/20], Step [150/164], Loss: 0.6995\n",
      "\n",
      "- FOLD:1 VALIDATION #5 START - TIME:0\n",
      "\n",
      "VALIDATION #5  Average Loss: 0.7246, mIoU: 0.5091, acc : 0.9257\n",
      "\n",
      "- FOLD:1 VALIDATION #5 DONE - TIME:109.8705644607544\n",
      "\n",
      "[mIoU] Best performance at epoch: 5\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:1 Epoch:5 Training DONE - TIME:784.4977633953094\n",
      "\n",
      "- Fold:1 Epoch:6 Training Start - TIME:0\n",
      "\n",
      "Epoch [6/20], Step [25/164], Loss: 0.6790\n",
      "Epoch [6/20], Step [50/164], Loss: 0.7216\n",
      "Epoch [6/20], Step [75/164], Loss: 0.7583\n",
      "Epoch [6/20], Step [100/164], Loss: 0.7448\n",
      "Epoch [6/20], Step [125/164], Loss: 0.6858\n",
      "Epoch [6/20], Step [150/164], Loss: 0.7577\n",
      "\n",
      "- FOLD:1 VALIDATION #6 START - TIME:0\n",
      "\n",
      "VALIDATION #6  Average Loss: 0.7220, mIoU: 0.5084, acc : 0.9274\n",
      "\n",
      "- FOLD:1 VALIDATION #6 DONE - TIME:111.34370183944702\n",
      "\n",
      "- Fold:1 Epoch:6 Training DONE - TIME:783.4480819702148\n",
      "\n",
      "- Fold:1 Epoch:7 Training Start - TIME:0\n",
      "\n",
      "Epoch [7/20], Step [25/164], Loss: 0.7179\n",
      "Epoch [7/20], Step [50/164], Loss: 0.6462\n",
      "Epoch [7/20], Step [75/164], Loss: 0.8059\n",
      "Epoch [7/20], Step [100/164], Loss: 0.6539\n",
      "Epoch [7/20], Step [125/164], Loss: 0.6963\n",
      "Epoch [7/20], Step [150/164], Loss: 0.7961\n",
      "\n",
      "- FOLD:1 VALIDATION #7 START - TIME:0\n",
      "\n",
      "VALIDATION #7  Average Loss: 0.7249, mIoU: 0.5858, acc : 0.9270\n",
      "\n",
      "- FOLD:1 VALIDATION #7 DONE - TIME:111.32597708702087\n",
      "\n",
      "[mIoU] Best performance at epoch: 7\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:1 Epoch:7 Training DONE - TIME:788.809779882431\n",
      "\n",
      "- Fold:1 Epoch:8 Training Start - TIME:0\n",
      "\n",
      "Epoch [8/20], Step [25/164], Loss: 0.6301\n",
      "Epoch [8/20], Step [50/164], Loss: 0.6787\n",
      "Epoch [8/20], Step [75/164], Loss: 0.6466\n",
      "Epoch [8/20], Step [100/164], Loss: 0.7818\n",
      "Epoch [8/20], Step [125/164], Loss: 0.6611\n",
      "Epoch [8/20], Step [150/164], Loss: 0.6512\n",
      "\n",
      "- FOLD:1 VALIDATION #8 START - TIME:0\n",
      "\n",
      "VALIDATION #8  Average Loss: 0.7214, mIoU: 0.5597, acc : 0.9267\n",
      "\n",
      "- FOLD:1 VALIDATION #8 DONE - TIME:110.21280407905579\n",
      "\n",
      "- Fold:1 Epoch:8 Training DONE - TIME:785.4385855197906\n",
      "\n",
      "- Fold:1 Epoch:9 Training Start - TIME:0\n",
      "\n",
      "Epoch [9/20], Step [25/164], Loss: 0.6577\n",
      "Epoch [9/20], Step [50/164], Loss: 0.6388\n",
      "Epoch [9/20], Step [75/164], Loss: 0.6516\n",
      "Epoch [9/20], Step [100/164], Loss: 0.6657\n",
      "Epoch [9/20], Step [125/164], Loss: 0.6490\n",
      "Epoch [9/20], Step [150/164], Loss: 0.6633\n",
      "\n",
      "- FOLD:1 VALIDATION #9 START - TIME:0\n",
      "\n",
      "VALIDATION #9  Average Loss: 0.7237, mIoU: 0.5944, acc : 0.9300\n",
      "\n",
      "- FOLD:1 VALIDATION #9 DONE - TIME:112.41756510734558\n",
      "\n",
      "[mIoU] Best performance at epoch: 9\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:1 Epoch:9 Training DONE - TIME:787.0045487880707\n",
      "\n",
      "- Fold:1 Epoch:10 Training Start - TIME:0\n",
      "\n",
      "Epoch [10/20], Step [25/164], Loss: 0.6241\n",
      "Epoch [10/20], Step [50/164], Loss: 0.6255\n",
      "Epoch [10/20], Step [75/164], Loss: 0.6216\n",
      "Epoch [10/20], Step [100/164], Loss: 0.7251\n",
      "Epoch [10/20], Step [125/164], Loss: 0.6502\n",
      "Epoch [10/20], Step [150/164], Loss: 0.6710\n",
      "\n",
      "- FOLD:1 VALIDATION #10 START - TIME:0\n",
      "\n",
      "VALIDATION #10  Average Loss: 0.7226, mIoU: 0.5826, acc : 0.9301\n",
      "\n",
      "- FOLD:1 VALIDATION #10 DONE - TIME:112.18194699287415\n",
      "\n",
      "- Fold:1 Epoch:10 Training DONE - TIME:783.9447376728058\n",
      "\n",
      "- Fold:1 Epoch:11 Training Start - TIME:0\n",
      "\n",
      "Epoch [11/20], Step [25/164], Loss: 0.7145\n",
      "Epoch [11/20], Step [50/164], Loss: 0.6476\n",
      "Epoch [11/20], Step [75/164], Loss: 0.6543\n",
      "Epoch [11/20], Step [100/164], Loss: 0.5910\n",
      "Epoch [11/20], Step [125/164], Loss: 0.6352\n",
      "Epoch [11/20], Step [150/164], Loss: 0.6934\n",
      "\n",
      "- FOLD:1 VALIDATION #11 START - TIME:0\n",
      "\n",
      "VALIDATION #11  Average Loss: 0.7178, mIoU: 0.5837, acc : 0.9288\n",
      "\n",
      "- FOLD:1 VALIDATION #11 DONE - TIME:110.61296510696411\n",
      "\n",
      "- Fold:1 Epoch:11 Training DONE - TIME:783.2417676448822\n",
      "\n",
      "- Fold:1 Epoch:12 Training Start - TIME:0\n",
      "\n",
      "Epoch [12/20], Step [25/164], Loss: 0.6466\n",
      "Epoch [12/20], Step [50/164], Loss: 0.6661\n",
      "Epoch [12/20], Step [75/164], Loss: 0.5967\n",
      "Epoch [12/20], Step [100/164], Loss: 0.6831\n",
      "Epoch [12/20], Step [125/164], Loss: 0.6145\n",
      "Epoch [12/20], Step [150/164], Loss: 0.6965\n",
      "\n",
      "- FOLD:1 VALIDATION #12 START - TIME:0\n",
      "\n",
      "VALIDATION #12  Average Loss: 0.7191, mIoU: 0.5961, acc : 0.9310\n",
      "\n",
      "- FOLD:1 VALIDATION #12 DONE - TIME:109.45305728912354\n",
      "\n",
      "[mIoU] Best performance at epoch: 12\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:1 Epoch:12 Training DONE - TIME:771.6789827346802\n",
      "\n",
      "- Fold:1 Epoch:13 Training Start - TIME:0\n",
      "\n",
      "Epoch [13/20], Step [25/164], Loss: 0.6476\n",
      "Epoch [13/20], Step [50/164], Loss: 0.6257\n",
      "Epoch [13/20], Step [75/164], Loss: 0.6061\n",
      "Epoch [13/20], Step [100/164], Loss: 0.6850\n",
      "Epoch [13/20], Step [125/164], Loss: 0.6132\n",
      "Epoch [13/20], Step [150/164], Loss: 0.6044\n",
      "\n",
      "- FOLD:1 VALIDATION #13 START - TIME:0\n",
      "\n",
      "VALIDATION #13  Average Loss: 0.7233, mIoU: 0.5984, acc : 0.9307\n",
      "\n",
      "- FOLD:1 VALIDATION #13 DONE - TIME:109.333988904953\n",
      "\n",
      "[mIoU] Best performance at epoch: 13\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:1 Epoch:13 Training DONE - TIME:777.2604203224182\n",
      "\n",
      "- Fold:1 Epoch:14 Training Start - TIME:0\n",
      "\n",
      "Epoch [14/20], Step [25/164], Loss: 0.6347\n",
      "Epoch [14/20], Step [50/164], Loss: 0.6065\n",
      "Epoch [14/20], Step [75/164], Loss: 0.6181\n",
      "Epoch [14/20], Step [100/164], Loss: 0.6322\n",
      "Epoch [14/20], Step [125/164], Loss: 0.6271\n",
      "Epoch [14/20], Step [150/164], Loss: 0.6240\n",
      "\n",
      "- FOLD:1 VALIDATION #14 START - TIME:0\n",
      "\n",
      "VALIDATION #14  Average Loss: 0.7219, mIoU: 0.5859, acc : 0.9296\n",
      "\n",
      "- FOLD:1 VALIDATION #14 DONE - TIME:110.14574599266052\n",
      "\n",
      "- Fold:1 Epoch:14 Training DONE - TIME:779.3993699550629\n",
      "\n",
      "- Fold:1 Epoch:15 Training Start - TIME:0\n",
      "\n",
      "Epoch [15/20], Step [25/164], Loss: 0.6227\n",
      "Epoch [15/20], Step [50/164], Loss: 0.6198\n",
      "Epoch [15/20], Step [75/164], Loss: 0.6330\n",
      "Epoch [15/20], Step [100/164], Loss: 0.6163\n",
      "Epoch [15/20], Step [125/164], Loss: 0.6400\n",
      "Epoch [15/20], Step [150/164], Loss: 0.5971\n",
      "\n",
      "- FOLD:1 VALIDATION #15 START - TIME:0\n",
      "\n",
      "VALIDATION #15  Average Loss: 0.7227, mIoU: 0.5900, acc : 0.9320\n",
      "\n",
      "- FOLD:1 VALIDATION #15 DONE - TIME:109.0550856590271\n",
      "\n",
      "- Fold:1 Epoch:15 Training DONE - TIME:783.7086136341095\n",
      "\n",
      "- Fold:1 Epoch:16 Training Start - TIME:0\n",
      "\n",
      "Epoch [16/20], Step [25/164], Loss: 0.6369\n",
      "Epoch [16/20], Step [50/164], Loss: 0.6470\n",
      "Epoch [16/20], Step [75/164], Loss: 0.5786\n",
      "Epoch [16/20], Step [100/164], Loss: 0.6519\n",
      "Epoch [16/20], Step [125/164], Loss: 0.6098\n",
      "Epoch [16/20], Step [150/164], Loss: 0.6210\n",
      "\n",
      "- FOLD:1 VALIDATION #16 START - TIME:0\n",
      "\n",
      "VALIDATION #16  Average Loss: 0.7190, mIoU: 0.5767, acc : 0.9311\n",
      "\n",
      "- FOLD:1 VALIDATION #16 DONE - TIME:110.2375841140747\n",
      "\n",
      "- Fold:1 Epoch:16 Training DONE - TIME:782.5911436080933\n",
      "\n",
      "- Fold:1 Epoch:17 Training Start - TIME:0\n",
      "\n",
      "Epoch [17/20], Step [25/164], Loss: 0.5964\n",
      "Epoch [17/20], Step [50/164], Loss: 0.6300\n",
      "Epoch [17/20], Step [75/164], Loss: 0.5990\n",
      "Epoch [17/20], Step [100/164], Loss: 0.6467\n",
      "Epoch [17/20], Step [125/164], Loss: 0.6609\n",
      "Epoch [17/20], Step [150/164], Loss: 0.6707\n",
      "\n",
      "- FOLD:1 VALIDATION #17 START - TIME:0\n",
      "\n",
      "VALIDATION #17  Average Loss: 0.7296, mIoU: 0.5683, acc : 0.9283\n",
      "\n",
      "- FOLD:1 VALIDATION #17 DONE - TIME:109.75243210792542\n",
      "\n",
      "- Fold:1 Epoch:17 Training DONE - TIME:779.0448956489563\n",
      "\n",
      "- Fold:1 Epoch:18 Training Start - TIME:0\n",
      "\n",
      "Epoch [18/20], Step [25/164], Loss: 0.6007\n",
      "Epoch [18/20], Step [50/164], Loss: 0.6152\n",
      "Epoch [18/20], Step [75/164], Loss: 0.6170\n",
      "Epoch [18/20], Step [100/164], Loss: 0.6557\n",
      "Epoch [18/20], Step [125/164], Loss: 0.6161\n",
      "Epoch [18/20], Step [150/164], Loss: 0.6051\n",
      "\n",
      "- FOLD:1 VALIDATION #18 START - TIME:0\n",
      "\n",
      "VALIDATION #18  Average Loss: 0.7263, mIoU: 0.5878, acc : 0.9307\n",
      "\n",
      "- FOLD:1 VALIDATION #18 DONE - TIME:110.89047837257385\n",
      "\n",
      "- Fold:1 Epoch:18 Training DONE - TIME:785.9283130168915\n",
      "\n",
      "- Fold:1 Epoch:19 Training Start - TIME:0\n",
      "\n",
      "Epoch [19/20], Step [25/164], Loss: 0.6060\n",
      "Epoch [19/20], Step [50/164], Loss: 0.6357\n",
      "Epoch [19/20], Step [75/164], Loss: 0.5962\n",
      "Epoch [19/20], Step [100/164], Loss: 0.6106\n",
      "Epoch [19/20], Step [125/164], Loss: 0.6358\n",
      "Epoch [19/20], Step [150/164], Loss: 0.6325\n",
      "\n",
      "- FOLD:1 VALIDATION #19 START - TIME:0\n",
      "\n",
      "VALIDATION #19  Average Loss: 0.7315, mIoU: 0.5867, acc : 0.9302\n",
      "\n",
      "- FOLD:1 VALIDATION #19 DONE - TIME:109.10376000404358\n",
      "\n",
      "- Fold:1 Epoch:19 Training DONE - TIME:780.97363448143\n",
      "\n",
      "- Fold:1 Epoch:20 Training Start - TIME:0\n",
      "\n",
      "Epoch [20/20], Step [25/164], Loss: 0.5951\n",
      "Epoch [20/20], Step [50/164], Loss: 0.6234\n",
      "Epoch [20/20], Step [75/164], Loss: 0.6101\n",
      "Epoch [20/20], Step [100/164], Loss: 0.5960\n",
      "Epoch [20/20], Step [125/164], Loss: 0.6174\n",
      "Epoch [20/20], Step [150/164], Loss: 0.6619\n",
      "\n",
      "- FOLD:1 VALIDATION #20 START - TIME:0\n",
      "\n",
      "VALIDATION #20  Average Loss: 0.7159, mIoU: 0.5922, acc : 0.9349\n",
      "\n",
      "- FOLD:1 VALIDATION #20 DONE - TIME:108.94536828994751\n",
      "\n",
      "- Fold:1 Epoch:20 Training DONE - TIME:774.1278166770935\n",
      "\n",
      "\n",
      "- Fold:1 Training DONE - TIME:15669.259880065918\n",
      "\n",
      "###### Fold:2 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=4.52s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.76s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:2 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:2 Training Start - TIME:0\n",
      "\n",
      "- Fold:2 Epoch:1 Training Start - TIME:0\n",
      "\n",
      "Epoch [1/20], Step [25/164], Loss: 1.6364\n",
      "Epoch [1/20], Step [50/164], Loss: 1.2001\n",
      "Epoch [1/20], Step [75/164], Loss: 1.1763\n",
      "Epoch [1/20], Step [100/164], Loss: 1.0771\n",
      "Epoch [1/20], Step [125/164], Loss: 0.9417\n",
      "Epoch [1/20], Step [150/164], Loss: 0.9697\n",
      "\n",
      "- FOLD:2 VALIDATION #1 START - TIME:0\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.8271, mIoU: 0.3889, acc : 0.8995\n",
      "\n",
      "- FOLD:2 VALIDATION #1 DONE - TIME:111.09499144554138\n",
      "\n",
      "[mIoU] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:1 Training DONE - TIME:785.6494088172913\n",
      "\n",
      "- Fold:2 Epoch:2 Training Start - TIME:0\n",
      "\n",
      "Epoch [2/20], Step [25/164], Loss: 0.9994\n",
      "Epoch [2/20], Step [50/164], Loss: 0.8165\n",
      "Epoch [2/20], Step [75/164], Loss: 0.8922\n",
      "Epoch [2/20], Step [100/164], Loss: 0.8832\n",
      "Epoch [2/20], Step [125/164], Loss: 0.7513\n",
      "Epoch [2/20], Step [150/164], Loss: 0.9463\n",
      "\n",
      "- FOLD:2 VALIDATION #2 START - TIME:0\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.7599, mIoU: 0.4499, acc : 0.9123\n",
      "\n",
      "- FOLD:2 VALIDATION #2 DONE - TIME:112.73838663101196\n",
      "\n",
      "[mIoU] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:2 Training DONE - TIME:788.5213677883148\n",
      "\n",
      "- Fold:2 Epoch:3 Training Start - TIME:0\n",
      "\n",
      "Epoch [3/20], Step [25/164], Loss: 0.8217\n",
      "Epoch [3/20], Step [50/164], Loss: 0.7785\n",
      "Epoch [3/20], Step [75/164], Loss: 0.7879\n",
      "Epoch [3/20], Step [100/164], Loss: 0.8663\n",
      "Epoch [3/20], Step [125/164], Loss: 0.8024\n",
      "Epoch [3/20], Step [150/164], Loss: 0.7177\n",
      "\n",
      "- FOLD:2 VALIDATION #3 START - TIME:0\n",
      "\n",
      "VALIDATION #3  Average Loss: 0.7455, mIoU: 0.4798, acc : 0.9179\n",
      "\n",
      "- FOLD:2 VALIDATION #3 DONE - TIME:107.3828227519989\n",
      "\n",
      "[mIoU] Best performance at epoch: 3\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:3 Training DONE - TIME:778.4600813388824\n",
      "\n",
      "- Fold:2 Epoch:4 Training Start - TIME:0\n",
      "\n",
      "Epoch [4/20], Step [25/164], Loss: 0.7758\n",
      "Epoch [4/20], Step [50/164], Loss: 0.7276\n",
      "Epoch [4/20], Step [75/164], Loss: 0.8163\n",
      "Epoch [4/20], Step [100/164], Loss: 0.8317\n",
      "Epoch [4/20], Step [125/164], Loss: 0.9059\n",
      "Epoch [4/20], Step [150/164], Loss: 0.8125\n",
      "\n",
      "- FOLD:2 VALIDATION #4 START - TIME:0\n",
      "\n",
      "VALIDATION #4  Average Loss: 0.7481, mIoU: 0.4880, acc : 0.9185\n",
      "\n",
      "- FOLD:2 VALIDATION #4 DONE - TIME:109.28332376480103\n",
      "\n",
      "[mIoU] Best performance at epoch: 4\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:4 Training DONE - TIME:783.4535644054413\n",
      "\n",
      "- Fold:2 Epoch:5 Training Start - TIME:0\n",
      "\n",
      "Epoch [5/20], Step [25/164], Loss: 0.9720\n",
      "Epoch [5/20], Step [50/164], Loss: 0.7117\n",
      "Epoch [5/20], Step [75/164], Loss: 0.6840\n",
      "Epoch [5/20], Step [100/164], Loss: 0.6715\n",
      "Epoch [5/20], Step [125/164], Loss: 0.7306\n",
      "Epoch [5/20], Step [150/164], Loss: 0.7684\n",
      "\n",
      "- FOLD:2 VALIDATION #5 START - TIME:0\n",
      "\n",
      "VALIDATION #5  Average Loss: 0.7439, mIoU: 0.4689, acc : 0.9202\n",
      "\n",
      "- FOLD:2 VALIDATION #5 DONE - TIME:108.80052709579468\n",
      "\n",
      "- Fold:2 Epoch:5 Training DONE - TIME:775.6285579204559\n",
      "\n",
      "- Fold:2 Epoch:6 Training Start - TIME:0\n",
      "\n",
      "Epoch [6/20], Step [25/164], Loss: 0.7044\n",
      "Epoch [6/20], Step [50/164], Loss: 0.6929\n",
      "Epoch [6/20], Step [75/164], Loss: 0.7503\n",
      "Epoch [6/20], Step [100/164], Loss: 0.6995\n",
      "Epoch [6/20], Step [125/164], Loss: 0.6661\n",
      "Epoch [6/20], Step [150/164], Loss: 0.6768\n",
      "\n",
      "- FOLD:2 VALIDATION #6 START - TIME:0\n",
      "\n",
      "VALIDATION #6  Average Loss: 0.7344, mIoU: 0.5351, acc : 0.9233\n",
      "\n",
      "- FOLD:2 VALIDATION #6 DONE - TIME:108.68468880653381\n",
      "\n",
      "[mIoU] Best performance at epoch: 6\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:6 Training DONE - TIME:780.936891078949\n",
      "\n",
      "- Fold:2 Epoch:7 Training Start - TIME:0\n",
      "\n",
      "Epoch [7/20], Step [25/164], Loss: 0.7540\n",
      "Epoch [7/20], Step [50/164], Loss: 0.6482\n",
      "Epoch [7/20], Step [75/164], Loss: 0.6429\n",
      "Epoch [7/20], Step [100/164], Loss: 0.6483\n",
      "Epoch [7/20], Step [125/164], Loss: 0.7295\n",
      "Epoch [7/20], Step [150/164], Loss: 0.6846\n",
      "\n",
      "- FOLD:2 VALIDATION #7 START - TIME:0\n",
      "\n",
      "VALIDATION #7  Average Loss: 0.7267, mIoU: 0.5555, acc : 0.9270\n",
      "\n",
      "- FOLD:2 VALIDATION #7 DONE - TIME:109.70643043518066\n",
      "\n",
      "[mIoU] Best performance at epoch: 7\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:7 Training DONE - TIME:776.3451089859009\n",
      "\n",
      "- Fold:2 Epoch:8 Training Start - TIME:0\n",
      "\n",
      "Epoch [8/20], Step [25/164], Loss: 0.6623\n",
      "Epoch [8/20], Step [50/164], Loss: 0.6665\n",
      "Epoch [8/20], Step [75/164], Loss: 0.6593\n",
      "Epoch [8/20], Step [100/164], Loss: 0.7469\n",
      "Epoch [8/20], Step [125/164], Loss: 0.6449\n",
      "Epoch [8/20], Step [150/164], Loss: 0.6755\n",
      "\n",
      "- FOLD:2 VALIDATION #8 START - TIME:0\n",
      "\n",
      "VALIDATION #8  Average Loss: 0.7186, mIoU: 0.5705, acc : 0.9301\n",
      "\n",
      "- FOLD:2 VALIDATION #8 DONE - TIME:108.82301235198975\n",
      "\n",
      "[mIoU] Best performance at epoch: 8\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:8 Training DONE - TIME:781.6142189502716\n",
      "\n",
      "- Fold:2 Epoch:9 Training Start - TIME:0\n",
      "\n",
      "Epoch [9/20], Step [25/164], Loss: 0.7065\n",
      "Epoch [9/20], Step [50/164], Loss: 0.6915\n",
      "Epoch [9/20], Step [75/164], Loss: 0.6058\n",
      "Epoch [9/20], Step [100/164], Loss: 0.7858\n",
      "Epoch [9/20], Step [125/164], Loss: 0.6757\n",
      "Epoch [9/20], Step [150/164], Loss: 0.6801\n",
      "\n",
      "- FOLD:2 VALIDATION #9 START - TIME:0\n",
      "\n",
      "VALIDATION #9  Average Loss: 0.7329, mIoU: 0.5457, acc : 0.9253\n",
      "\n",
      "- FOLD:2 VALIDATION #9 DONE - TIME:108.45363306999207\n",
      "\n",
      "- Fold:2 Epoch:9 Training DONE - TIME:776.1136240959167\n",
      "\n",
      "- Fold:2 Epoch:10 Training Start - TIME:0\n",
      "\n",
      "Epoch [10/20], Step [25/164], Loss: 0.6554\n",
      "Epoch [10/20], Step [50/164], Loss: 0.6947\n",
      "Epoch [10/20], Step [75/164], Loss: 0.6847\n",
      "Epoch [10/20], Step [100/164], Loss: 0.7312\n",
      "Epoch [10/20], Step [125/164], Loss: 0.6446\n",
      "Epoch [10/20], Step [150/164], Loss: 0.6512\n",
      "\n",
      "- FOLD:2 VALIDATION #10 START - TIME:0\n",
      "\n",
      "VALIDATION #10  Average Loss: 0.7158, mIoU: 0.5768, acc : 0.9311\n",
      "\n",
      "- FOLD:2 VALIDATION #10 DONE - TIME:108.75281739234924\n",
      "\n",
      "[mIoU] Best performance at epoch: 10\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:10 Training DONE - TIME:773.03009724617\n",
      "\n",
      "- Fold:2 Epoch:11 Training Start - TIME:0\n",
      "\n",
      "Epoch [11/20], Step [25/164], Loss: 0.6494\n",
      "Epoch [11/20], Step [50/164], Loss: 0.6483\n",
      "Epoch [11/20], Step [75/164], Loss: 0.6728\n",
      "Epoch [11/20], Step [100/164], Loss: 0.6189\n",
      "Epoch [11/20], Step [125/164], Loss: 0.6202\n",
      "Epoch [11/20], Step [150/164], Loss: 0.6351\n",
      "\n",
      "- FOLD:2 VALIDATION #11 START - TIME:0\n",
      "\n",
      "VALIDATION #11  Average Loss: 0.7215, mIoU: 0.5685, acc : 0.9314\n",
      "\n",
      "- FOLD:2 VALIDATION #11 DONE - TIME:111.6548364162445\n",
      "\n",
      "- Fold:2 Epoch:11 Training DONE - TIME:774.5562291145325\n",
      "\n",
      "- Fold:2 Epoch:12 Training Start - TIME:0\n",
      "\n",
      "Epoch [12/20], Step [25/164], Loss: 0.6081\n",
      "Epoch [12/20], Step [50/164], Loss: 0.6576\n",
      "Epoch [12/20], Step [75/164], Loss: 0.6438\n",
      "Epoch [12/20], Step [100/164], Loss: 0.6206\n",
      "Epoch [12/20], Step [125/164], Loss: 0.6276\n",
      "Epoch [12/20], Step [150/164], Loss: 0.6125\n",
      "\n",
      "- FOLD:2 VALIDATION #12 START - TIME:0\n",
      "\n",
      "VALIDATION #12  Average Loss: 0.7205, mIoU: 0.5802, acc : 0.9306\n",
      "\n",
      "- FOLD:2 VALIDATION #12 DONE - TIME:107.64791560173035\n",
      "\n",
      "[mIoU] Best performance at epoch: 12\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:12 Training DONE - TIME:779.253589630127\n",
      "\n",
      "- Fold:2 Epoch:13 Training Start - TIME:0\n",
      "\n",
      "Epoch [13/20], Step [25/164], Loss: 0.5911\n",
      "Epoch [13/20], Step [50/164], Loss: 0.6166\n",
      "Epoch [13/20], Step [75/164], Loss: 0.6547\n",
      "Epoch [13/20], Step [100/164], Loss: 0.6518\n",
      "Epoch [13/20], Step [125/164], Loss: 0.6944\n",
      "Epoch [13/20], Step [150/164], Loss: 0.5882\n",
      "\n",
      "- FOLD:2 VALIDATION #13 START - TIME:0\n",
      "\n",
      "VALIDATION #13  Average Loss: 0.7188, mIoU: 0.5754, acc : 0.9324\n",
      "\n",
      "- FOLD:2 VALIDATION #13 DONE - TIME:108.36743497848511\n",
      "\n",
      "- Fold:2 Epoch:13 Training DONE - TIME:782.3040363788605\n",
      "\n",
      "- Fold:2 Epoch:14 Training Start - TIME:0\n",
      "\n",
      "Epoch [14/20], Step [25/164], Loss: 0.7043\n",
      "Epoch [14/20], Step [50/164], Loss: 0.5954\n",
      "Epoch [14/20], Step [75/164], Loss: 0.6566\n",
      "Epoch [14/20], Step [100/164], Loss: 0.6012\n",
      "Epoch [14/20], Step [125/164], Loss: 0.6034\n",
      "Epoch [14/20], Step [150/164], Loss: 0.6239\n",
      "\n",
      "- FOLD:2 VALIDATION #14 START - TIME:0\n",
      "\n",
      "VALIDATION #14  Average Loss: 0.7164, mIoU: 0.5837, acc : 0.9327\n",
      "\n",
      "- FOLD:2 VALIDATION #14 DONE - TIME:108.65385293960571\n",
      "\n",
      "[mIoU] Best performance at epoch: 14\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:2 Epoch:14 Training DONE - TIME:777.8302376270294\n",
      "\n",
      "- Fold:2 Epoch:15 Training Start - TIME:0\n",
      "\n",
      "Epoch [15/20], Step [25/164], Loss: 0.5925\n",
      "Epoch [15/20], Step [50/164], Loss: 0.6457\n",
      "Epoch [15/20], Step [75/164], Loss: 0.6358\n",
      "Epoch [15/20], Step [100/164], Loss: 0.6287\n",
      "Epoch [15/20], Step [125/164], Loss: 0.6527\n",
      "Epoch [15/20], Step [150/164], Loss: 0.6169\n",
      "\n",
      "- FOLD:2 VALIDATION #15 START - TIME:0\n",
      "\n",
      "VALIDATION #15  Average Loss: 0.7176, mIoU: 0.5700, acc : 0.9329\n",
      "\n",
      "- FOLD:2 VALIDATION #15 DONE - TIME:107.78414249420166\n",
      "\n",
      "- Fold:2 Epoch:15 Training DONE - TIME:769.3658149242401\n",
      "\n",
      "- Fold:2 Epoch:16 Training Start - TIME:0\n",
      "\n",
      "Epoch [16/20], Step [25/164], Loss: 0.5949\n",
      "Epoch [16/20], Step [50/164], Loss: 0.6611\n",
      "Epoch [16/20], Step [75/164], Loss: 0.6413\n",
      "Epoch [16/20], Step [100/164], Loss: 0.6551\n",
      "Epoch [16/20], Step [125/164], Loss: 0.6380\n",
      "Epoch [16/20], Step [150/164], Loss: 0.6714\n",
      "\n",
      "- FOLD:2 VALIDATION #16 START - TIME:0\n",
      "\n",
      "VALIDATION #16  Average Loss: 0.7251, mIoU: 0.5651, acc : 0.9299\n",
      "\n",
      "- FOLD:2 VALIDATION #16 DONE - TIME:109.80346465110779\n",
      "\n",
      "- Fold:2 Epoch:16 Training DONE - TIME:773.8269348144531\n",
      "\n",
      "- Fold:2 Epoch:17 Training Start - TIME:0\n",
      "\n",
      "Epoch [17/20], Step [25/164], Loss: 0.6366\n",
      "Epoch [17/20], Step [50/164], Loss: 0.6044\n",
      "Epoch [17/20], Step [75/164], Loss: 0.6406\n",
      "Epoch [17/20], Step [100/164], Loss: 0.6012\n",
      "Epoch [17/20], Step [125/164], Loss: 0.6058\n",
      "Epoch [17/20], Step [150/164], Loss: 0.6352\n",
      "\n",
      "- FOLD:2 VALIDATION #17 START - TIME:0\n",
      "\n",
      "VALIDATION #17  Average Loss: 0.7260, mIoU: 0.5741, acc : 0.9305\n",
      "\n",
      "- FOLD:2 VALIDATION #17 DONE - TIME:110.02188491821289\n",
      "\n",
      "- Fold:2 Epoch:17 Training DONE - TIME:771.6599984169006\n",
      "\n",
      "- Fold:2 Epoch:18 Training Start - TIME:0\n",
      "\n",
      "Epoch [18/20], Step [25/164], Loss: 0.5865\n",
      "Epoch [18/20], Step [50/164], Loss: 0.6076\n",
      "Epoch [18/20], Step [75/164], Loss: 0.6418\n",
      "Epoch [18/20], Step [100/164], Loss: 0.6149\n",
      "Epoch [18/20], Step [125/164], Loss: 0.5981\n",
      "Epoch [18/20], Step [150/164], Loss: 0.6386\n",
      "\n",
      "- FOLD:2 VALIDATION #18 START - TIME:0\n",
      "\n",
      "VALIDATION #18  Average Loss: 0.7314, mIoU: 0.5631, acc : 0.9302\n",
      "\n",
      "- FOLD:2 VALIDATION #18 DONE - TIME:109.95444893836975\n",
      "\n",
      "- Fold:2 Epoch:18 Training DONE - TIME:774.7042548656464\n",
      "\n",
      "- Fold:2 Epoch:19 Training Start - TIME:0\n",
      "\n",
      "Epoch [19/20], Step [25/164], Loss: 0.5972\n",
      "Epoch [19/20], Step [50/164], Loss: 0.6034\n",
      "Epoch [19/20], Step [75/164], Loss: 0.6177\n",
      "Epoch [19/20], Step [100/164], Loss: 0.5703\n",
      "Epoch [19/20], Step [125/164], Loss: 0.6347\n",
      "Epoch [19/20], Step [150/164], Loss: 0.6295\n",
      "\n",
      "- FOLD:2 VALIDATION #19 START - TIME:0\n",
      "\n",
      "VALIDATION #19  Average Loss: 0.7208, mIoU: 0.5607, acc : 0.9313\n",
      "\n",
      "- FOLD:2 VALIDATION #19 DONE - TIME:109.71152257919312\n",
      "\n",
      "- Fold:2 Epoch:19 Training DONE - TIME:774.9598178863525\n",
      "\n",
      "- Fold:2 Epoch:20 Training Start - TIME:0\n",
      "\n",
      "Epoch [20/20], Step [25/164], Loss: 0.6182\n",
      "Epoch [20/20], Step [50/164], Loss: 0.6002\n",
      "Epoch [20/20], Step [75/164], Loss: 0.6094\n",
      "Epoch [20/20], Step [100/164], Loss: 0.6058\n",
      "Epoch [20/20], Step [125/164], Loss: 0.6193\n",
      "Epoch [20/20], Step [150/164], Loss: 0.6063\n",
      "\n",
      "- FOLD:2 VALIDATION #20 START - TIME:0\n",
      "\n",
      "VALIDATION #20  Average Loss: 0.7259, mIoU: 0.5748, acc : 0.9309\n",
      "\n",
      "- FOLD:2 VALIDATION #20 DONE - TIME:110.64949655532837\n",
      "\n",
      "- Fold:2 Epoch:20 Training DONE - TIME:775.0625536441803\n",
      "\n",
      "\n",
      "- Fold:2 Training DONE - TIME:15553.337418079376\n",
      "\n",
      "###### Fold:3 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=4.76s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.93s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:3 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:3 Training Start - TIME:0\n",
      "\n",
      "- Fold:3 Epoch:1 Training Start - TIME:0\n",
      "\n",
      "Epoch [1/20], Step [25/164], Loss: 1.6123\n",
      "Epoch [1/20], Step [50/164], Loss: 1.3423\n",
      "Epoch [1/20], Step [75/164], Loss: 1.1321\n",
      "Epoch [1/20], Step [100/164], Loss: 1.2409\n",
      "Epoch [1/20], Step [125/164], Loss: 0.9247\n",
      "Epoch [1/20], Step [150/164], Loss: 0.9066\n",
      "\n",
      "- FOLD:3 VALIDATION #1 START - TIME:0\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.8033, mIoU: 0.3531, acc : 0.8988\n",
      "\n",
      "- FOLD:3 VALIDATION #1 DONE - TIME:107.69876551628113\n",
      "\n",
      "[mIoU] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:1 Training DONE - TIME:773.395537853241\n",
      "\n",
      "- Fold:3 Epoch:2 Training Start - TIME:0\n",
      "\n",
      "Epoch [2/20], Step [25/164], Loss: 0.7947\n",
      "Epoch [2/20], Step [50/164], Loss: 0.9855\n",
      "Epoch [2/20], Step [75/164], Loss: 0.7666\n",
      "Epoch [2/20], Step [100/164], Loss: 0.9171\n",
      "Epoch [2/20], Step [125/164], Loss: 0.8285\n",
      "Epoch [2/20], Step [150/164], Loss: 0.9038\n",
      "\n",
      "- FOLD:3 VALIDATION #2 START - TIME:0\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.7515, mIoU: 0.4619, acc : 0.9146\n",
      "\n",
      "- FOLD:3 VALIDATION #2 DONE - TIME:109.52213263511658\n",
      "\n",
      "[mIoU] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:2 Training DONE - TIME:775.8693988323212\n",
      "\n",
      "- Fold:3 Epoch:3 Training Start - TIME:0\n",
      "\n",
      "Epoch [3/20], Step [25/164], Loss: 0.7489\n",
      "Epoch [3/20], Step [50/164], Loss: 0.8090\n",
      "Epoch [3/20], Step [75/164], Loss: 0.7909\n",
      "Epoch [3/20], Step [100/164], Loss: 0.8741\n",
      "Epoch [3/20], Step [125/164], Loss: 0.7726\n",
      "Epoch [3/20], Step [150/164], Loss: 0.7678\n",
      "\n",
      "- FOLD:3 VALIDATION #3 START - TIME:0\n",
      "\n",
      "VALIDATION #3  Average Loss: 0.7434, mIoU: 0.4661, acc : 0.9163\n",
      "\n",
      "- FOLD:3 VALIDATION #3 DONE - TIME:107.40849947929382\n",
      "\n",
      "[mIoU] Best performance at epoch: 3\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:3 Training DONE - TIME:772.1331057548523\n",
      "\n",
      "- Fold:3 Epoch:4 Training Start - TIME:0\n",
      "\n",
      "Epoch [4/20], Step [25/164], Loss: 0.6660\n",
      "Epoch [4/20], Step [50/164], Loss: 0.7480\n",
      "Epoch [4/20], Step [75/164], Loss: 0.7518\n",
      "Epoch [4/20], Step [100/164], Loss: 0.8405\n",
      "Epoch [4/20], Step [125/164], Loss: 0.7974\n",
      "Epoch [4/20], Step [150/164], Loss: 0.7095\n",
      "\n",
      "- FOLD:3 VALIDATION #4 START - TIME:0\n",
      "\n",
      "VALIDATION #4  Average Loss: 0.7268, mIoU: 0.5023, acc : 0.9242\n",
      "\n",
      "- FOLD:3 VALIDATION #4 DONE - TIME:108.87658166885376\n",
      "\n",
      "[mIoU] Best performance at epoch: 4\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:4 Training DONE - TIME:774.3835544586182\n",
      "\n",
      "- Fold:3 Epoch:5 Training Start - TIME:0\n",
      "\n",
      "Epoch [5/20], Step [25/164], Loss: 0.7030\n",
      "Epoch [5/20], Step [50/164], Loss: 0.6989\n",
      "Epoch [5/20], Step [75/164], Loss: 0.7075\n",
      "Epoch [5/20], Step [100/164], Loss: 0.6944\n",
      "Epoch [5/20], Step [125/164], Loss: 0.7170\n",
      "Epoch [5/20], Step [150/164], Loss: 0.7716\n",
      "\n",
      "- FOLD:3 VALIDATION #5 START - TIME:0\n",
      "\n",
      "VALIDATION #5  Average Loss: 0.7362, mIoU: 0.5580, acc : 0.9210\n",
      "\n",
      "- FOLD:3 VALIDATION #5 DONE - TIME:108.30771446228027\n",
      "\n",
      "[mIoU] Best performance at epoch: 5\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:5 Training DONE - TIME:778.8970086574554\n",
      "\n",
      "- Fold:3 Epoch:6 Training Start - TIME:0\n",
      "\n",
      "Epoch [6/20], Step [25/164], Loss: 0.7004\n",
      "Epoch [6/20], Step [50/164], Loss: 0.7719\n",
      "Epoch [6/20], Step [75/164], Loss: 0.6428\n",
      "Epoch [6/20], Step [100/164], Loss: 0.6960\n",
      "Epoch [6/20], Step [125/164], Loss: 0.6989\n",
      "Epoch [6/20], Step [150/164], Loss: 0.7412\n",
      "\n",
      "- FOLD:3 VALIDATION #6 START - TIME:0\n",
      "\n",
      "VALIDATION #6  Average Loss: 0.7275, mIoU: 0.5642, acc : 0.9250\n",
      "\n",
      "- FOLD:3 VALIDATION #6 DONE - TIME:106.58450102806091\n",
      "\n",
      "[mIoU] Best performance at epoch: 6\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:6 Training DONE - TIME:772.7118747234344\n",
      "\n",
      "- Fold:3 Epoch:7 Training Start - TIME:0\n",
      "\n",
      "Epoch [7/20], Step [25/164], Loss: 0.7303\n",
      "Epoch [7/20], Step [50/164], Loss: 0.6293\n",
      "Epoch [7/20], Step [75/164], Loss: 0.7135\n",
      "Epoch [7/20], Step [100/164], Loss: 0.6868\n",
      "Epoch [7/20], Step [125/164], Loss: 0.7043\n",
      "Epoch [7/20], Step [150/164], Loss: 0.7055\n",
      "\n",
      "- FOLD:3 VALIDATION #7 START - TIME:0\n",
      "\n",
      "VALIDATION #7  Average Loss: 0.7213, mIoU: 0.5859, acc : 0.9281\n",
      "\n",
      "- FOLD:3 VALIDATION #7 DONE - TIME:112.95822048187256\n",
      "\n",
      "[mIoU] Best performance at epoch: 7\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:7 Training DONE - TIME:792.0914626121521\n",
      "\n",
      "- Fold:3 Epoch:8 Training Start - TIME:0\n",
      "\n",
      "Epoch [8/20], Step [25/164], Loss: 0.6794\n",
      "Epoch [8/20], Step [50/164], Loss: 0.6295\n",
      "Epoch [8/20], Step [75/164], Loss: 0.6483\n",
      "Epoch [8/20], Step [100/164], Loss: 0.7421\n",
      "Epoch [8/20], Step [125/164], Loss: 0.6747\n",
      "Epoch [8/20], Step [150/164], Loss: 0.6497\n",
      "\n",
      "- FOLD:3 VALIDATION #8 START - TIME:0\n",
      "\n",
      "VALIDATION #8  Average Loss: 0.7148, mIoU: 0.6046, acc : 0.9329\n",
      "\n",
      "- FOLD:3 VALIDATION #8 DONE - TIME:107.57310557365417\n",
      "\n",
      "[mIoU] Best performance at epoch: 8\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:8 Training DONE - TIME:770.575522184372\n",
      "\n",
      "- Fold:3 Epoch:9 Training Start - TIME:0\n",
      "\n",
      "Epoch [9/20], Step [25/164], Loss: 0.6305\n",
      "Epoch [9/20], Step [50/164], Loss: 0.6399\n",
      "Epoch [9/20], Step [75/164], Loss: 0.6669\n",
      "Epoch [9/20], Step [100/164], Loss: 0.6885\n",
      "Epoch [9/20], Step [125/164], Loss: 0.6454\n",
      "Epoch [9/20], Step [150/164], Loss: 0.6719\n",
      "\n",
      "- FOLD:3 VALIDATION #9 START - TIME:0\n",
      "\n",
      "VALIDATION #9  Average Loss: 0.7206, mIoU: 0.6059, acc : 0.9307\n",
      "\n",
      "- FOLD:3 VALIDATION #9 DONE - TIME:108.35412240028381\n",
      "\n",
      "[mIoU] Best performance at epoch: 9\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:9 Training DONE - TIME:780.1048078536987\n",
      "\n",
      "- Fold:3 Epoch:10 Training Start - TIME:0\n",
      "\n",
      "Epoch [10/20], Step [25/164], Loss: 0.6808\n",
      "Epoch [10/20], Step [50/164], Loss: 0.6668\n",
      "Epoch [10/20], Step [75/164], Loss: 0.6233\n",
      "Epoch [10/20], Step [100/164], Loss: 0.6361\n",
      "Epoch [10/20], Step [125/164], Loss: 0.6644\n",
      "Epoch [10/20], Step [150/164], Loss: 0.6525\n",
      "\n",
      "- FOLD:3 VALIDATION #10 START - TIME:0\n",
      "\n",
      "VALIDATION #10  Average Loss: 0.7123, mIoU: 0.5990, acc : 0.9324\n",
      "\n",
      "- FOLD:3 VALIDATION #10 DONE - TIME:108.7257297039032\n",
      "\n",
      "- Fold:3 Epoch:10 Training DONE - TIME:778.4441623687744\n",
      "\n",
      "- Fold:3 Epoch:11 Training Start - TIME:0\n",
      "\n",
      "Epoch [11/20], Step [25/164], Loss: 0.6550\n",
      "Epoch [11/20], Step [50/164], Loss: 0.6431\n",
      "Epoch [11/20], Step [75/164], Loss: 0.6952\n",
      "Epoch [11/20], Step [100/164], Loss: 0.6401\n",
      "Epoch [11/20], Step [125/164], Loss: 0.7061\n",
      "Epoch [11/20], Step [150/164], Loss: 0.6083\n",
      "\n",
      "- FOLD:3 VALIDATION #11 START - TIME:0\n",
      "\n",
      "VALIDATION #11  Average Loss: 0.7202, mIoU: 0.6037, acc : 0.9300\n",
      "\n",
      "- FOLD:3 VALIDATION #11 DONE - TIME:107.55694460868835\n",
      "\n",
      "- Fold:3 Epoch:11 Training DONE - TIME:780.7604985237122\n",
      "\n",
      "- Fold:3 Epoch:12 Training Start - TIME:0\n",
      "\n",
      "Epoch [12/20], Step [25/164], Loss: 0.6361\n",
      "Epoch [12/20], Step [50/164], Loss: 0.6248\n",
      "Epoch [12/20], Step [75/164], Loss: 0.6346\n",
      "Epoch [12/20], Step [100/164], Loss: 0.6080\n",
      "Epoch [12/20], Step [125/164], Loss: 0.7900\n",
      "Epoch [12/20], Step [150/164], Loss: 0.7272\n",
      "\n",
      "- FOLD:3 VALIDATION #12 START - TIME:0\n",
      "\n",
      "VALIDATION #12  Average Loss: 0.7145, mIoU: 0.6103, acc : 0.9325\n",
      "\n",
      "- FOLD:3 VALIDATION #12 DONE - TIME:109.97338676452637\n",
      "\n",
      "[mIoU] Best performance at epoch: 12\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:12 Training DONE - TIME:787.1549205780029\n",
      "\n",
      "- Fold:3 Epoch:13 Training Start - TIME:0\n",
      "\n",
      "Epoch [13/20], Step [25/164], Loss: 0.6168\n",
      "Epoch [13/20], Step [50/164], Loss: 0.6225\n",
      "Epoch [13/20], Step [75/164], Loss: 0.6347\n",
      "Epoch [13/20], Step [100/164], Loss: 0.6417\n",
      "Epoch [13/20], Step [125/164], Loss: 0.6279\n",
      "Epoch [13/20], Step [150/164], Loss: 0.5974\n",
      "\n",
      "- FOLD:3 VALIDATION #13 START - TIME:0\n",
      "\n",
      "VALIDATION #13  Average Loss: 0.7288, mIoU: 0.5917, acc : 0.9287\n",
      "\n",
      "- FOLD:3 VALIDATION #13 DONE - TIME:108.67030930519104\n",
      "\n",
      "- Fold:3 Epoch:13 Training DONE - TIME:778.2059345245361\n",
      "\n",
      "- Fold:3 Epoch:14 Training Start - TIME:0\n",
      "\n",
      "Epoch [14/20], Step [25/164], Loss: 0.6167\n",
      "Epoch [14/20], Step [50/164], Loss: 0.6377\n",
      "Epoch [14/20], Step [75/164], Loss: 0.5725\n",
      "Epoch [14/20], Step [100/164], Loss: 0.6119\n",
      "Epoch [14/20], Step [125/164], Loss: 0.6189\n",
      "Epoch [14/20], Step [150/164], Loss: 0.6280\n",
      "\n",
      "- FOLD:3 VALIDATION #14 START - TIME:0\n",
      "\n",
      "VALIDATION #14  Average Loss: 0.7180, mIoU: 0.5908, acc : 0.9317\n",
      "\n",
      "- FOLD:3 VALIDATION #14 DONE - TIME:109.08651065826416\n",
      "\n",
      "- Fold:3 Epoch:14 Training DONE - TIME:795.3648216724396\n",
      "\n",
      "- Fold:3 Epoch:15 Training Start - TIME:0\n",
      "\n",
      "Epoch [15/20], Step [25/164], Loss: 0.6421\n",
      "Epoch [15/20], Step [50/164], Loss: 0.6911\n",
      "Epoch [15/20], Step [75/164], Loss: 0.6162\n",
      "Epoch [15/20], Step [100/164], Loss: 0.6650\n",
      "Epoch [15/20], Step [125/164], Loss: 0.6354\n",
      "Epoch [15/20], Step [150/164], Loss: 0.6375\n",
      "\n",
      "- FOLD:3 VALIDATION #15 START - TIME:0\n",
      "\n",
      "VALIDATION #15  Average Loss: 0.7229, mIoU: 0.6060, acc : 0.9307\n",
      "\n",
      "- FOLD:3 VALIDATION #15 DONE - TIME:114.18831825256348\n",
      "\n",
      "- Fold:3 Epoch:15 Training DONE - TIME:806.1260879039764\n",
      "\n",
      "- Fold:3 Epoch:16 Training Start - TIME:0\n",
      "\n",
      "Epoch [16/20], Step [25/164], Loss: 0.5908\n",
      "Epoch [16/20], Step [50/164], Loss: 0.5964\n",
      "Epoch [16/20], Step [75/164], Loss: 0.6506\n",
      "Epoch [16/20], Step [100/164], Loss: 0.6016\n",
      "Epoch [16/20], Step [125/164], Loss: 0.6687\n",
      "Epoch [16/20], Step [150/164], Loss: 0.6121\n",
      "\n",
      "- FOLD:3 VALIDATION #16 START - TIME:0\n",
      "\n",
      "VALIDATION #16  Average Loss: 0.7160, mIoU: 0.6009, acc : 0.9337\n",
      "\n",
      "- FOLD:3 VALIDATION #16 DONE - TIME:109.72306966781616\n",
      "\n",
      "- Fold:3 Epoch:16 Training DONE - TIME:798.8302783966064\n",
      "\n",
      "- Fold:3 Epoch:17 Training Start - TIME:0\n",
      "\n",
      "Epoch [17/20], Step [25/164], Loss: 0.6828\n",
      "Epoch [17/20], Step [50/164], Loss: 0.6182\n",
      "Epoch [17/20], Step [75/164], Loss: 0.6352\n",
      "Epoch [17/20], Step [100/164], Loss: 0.6389\n",
      "Epoch [17/20], Step [125/164], Loss: 0.6166\n",
      "Epoch [17/20], Step [150/164], Loss: 0.6251\n",
      "\n",
      "- FOLD:3 VALIDATION #17 START - TIME:0\n",
      "\n",
      "VALIDATION #17  Average Loss: 0.7144, mIoU: 0.6261, acc : 0.9352\n",
      "\n",
      "- FOLD:3 VALIDATION #17 DONE - TIME:109.97682619094849\n",
      "\n",
      "[mIoU] Best performance at epoch: 17\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:3 Epoch:17 Training DONE - TIME:782.6689937114716\n",
      "\n",
      "- Fold:3 Epoch:18 Training Start - TIME:0\n",
      "\n",
      "Epoch [18/20], Step [25/164], Loss: 0.6505\n",
      "Epoch [18/20], Step [50/164], Loss: 0.5922\n",
      "Epoch [18/20], Step [75/164], Loss: 0.6006\n",
      "Epoch [18/20], Step [100/164], Loss: 0.6118\n",
      "Epoch [18/20], Step [125/164], Loss: 0.6182\n",
      "Epoch [18/20], Step [150/164], Loss: 0.6101\n",
      "\n",
      "- FOLD:3 VALIDATION #18 START - TIME:0\n",
      "\n",
      "VALIDATION #18  Average Loss: 0.7076, mIoU: 0.6232, acc : 0.9362\n",
      "\n",
      "- FOLD:3 VALIDATION #18 DONE - TIME:107.64100408554077\n",
      "\n",
      "- Fold:3 Epoch:18 Training DONE - TIME:778.3679654598236\n",
      "\n",
      "- Fold:3 Epoch:19 Training Start - TIME:0\n",
      "\n",
      "Epoch [19/20], Step [25/164], Loss: 0.6194\n",
      "Epoch [19/20], Step [50/164], Loss: 0.6541\n",
      "Epoch [19/20], Step [75/164], Loss: 0.6245\n",
      "Epoch [19/20], Step [100/164], Loss: 0.6106\n",
      "Epoch [19/20], Step [125/164], Loss: 0.6449\n",
      "Epoch [19/20], Step [150/164], Loss: 0.6151\n",
      "\n",
      "- FOLD:3 VALIDATION #19 START - TIME:0\n",
      "\n",
      "VALIDATION #19  Average Loss: 0.7169, mIoU: 0.6218, acc : 0.9361\n",
      "\n",
      "- FOLD:3 VALIDATION #19 DONE - TIME:112.83645915985107\n",
      "\n",
      "- Fold:3 Epoch:19 Training DONE - TIME:795.3333034515381\n",
      "\n",
      "- Fold:3 Epoch:20 Training Start - TIME:0\n",
      "\n",
      "Epoch [20/20], Step [25/164], Loss: 0.5963\n",
      "Epoch [20/20], Step [50/164], Loss: 0.5845\n",
      "Epoch [20/20], Step [75/164], Loss: 0.6223\n",
      "Epoch [20/20], Step [100/164], Loss: 0.6495\n",
      "Epoch [20/20], Step [125/164], Loss: 0.5923\n",
      "Epoch [20/20], Step [150/164], Loss: 0.5825\n",
      "\n",
      "- FOLD:3 VALIDATION #20 START - TIME:0\n",
      "\n",
      "VALIDATION #20  Average Loss: 0.7167, mIoU: 0.6147, acc : 0.9339\n",
      "\n",
      "- FOLD:3 VALIDATION #20 DONE - TIME:114.03153324127197\n",
      "\n",
      "- Fold:3 Epoch:20 Training DONE - TIME:798.5559754371643\n",
      "\n",
      "\n",
      "- Fold:3 Training DONE - TIME:15670.03460741043\n",
      "\n",
      "###### Fold:4 - Loading Dataset ######\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=4.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.71s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "###### Fold:4 - Loading Dataset - DONE ######\n",
      "\n",
      "- Fold:4 Training Start - TIME:0\n",
      "\n",
      "- Fold:4 Epoch:1 Training Start - TIME:0\n",
      "\n",
      "Epoch [1/20], Step [25/164], Loss: 1.4184\n",
      "Epoch [1/20], Step [50/164], Loss: 1.0497\n",
      "Epoch [1/20], Step [75/164], Loss: 1.2966\n",
      "Epoch [1/20], Step [100/164], Loss: 1.0115\n",
      "Epoch [1/20], Step [125/164], Loss: 0.8508\n",
      "Epoch [1/20], Step [150/164], Loss: 0.8733\n",
      "\n",
      "- FOLD:4 VALIDATION #1 START - TIME:0\n",
      "\n",
      "VALIDATION #1  Average Loss: 0.8045, mIoU: 0.4049, acc : 0.8986\n",
      "\n",
      "- FOLD:4 VALIDATION #1 DONE - TIME:112.34985566139221\n",
      "\n",
      "[mIoU] Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:4 Epoch:1 Training DONE - TIME:796.4626679420471\n",
      "\n",
      "- Fold:4 Epoch:2 Training Start - TIME:0\n",
      "\n",
      "Epoch [2/20], Step [25/164], Loss: 0.8396\n",
      "Epoch [2/20], Step [50/164], Loss: 0.9831\n",
      "Epoch [2/20], Step [75/164], Loss: 0.9776\n",
      "Epoch [2/20], Step [100/164], Loss: 0.8373\n",
      "Epoch [2/20], Step [125/164], Loss: 0.8036\n",
      "Epoch [2/20], Step [150/164], Loss: 0.9128\n",
      "\n",
      "- FOLD:4 VALIDATION #2 START - TIME:0\n",
      "\n",
      "VALIDATION #2  Average Loss: 0.7819, mIoU: 0.4086, acc : 0.9045\n",
      "\n",
      "- FOLD:4 VALIDATION #2 DONE - TIME:108.5075888633728\n",
      "\n",
      "[mIoU] Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:4 Epoch:2 Training DONE - TIME:789.3085923194885\n",
      "\n",
      "- Fold:4 Epoch:3 Training Start - TIME:0\n",
      "\n",
      "Epoch [3/20], Step [25/164], Loss: 0.8479\n",
      "Epoch [3/20], Step [50/164], Loss: 0.8204\n",
      "Epoch [3/20], Step [75/164], Loss: 0.7899\n",
      "Epoch [3/20], Step [100/164], Loss: 0.8041\n",
      "Epoch [3/20], Step [125/164], Loss: 0.8442\n",
      "Epoch [3/20], Step [150/164], Loss: 0.8341\n",
      "\n",
      "- FOLD:4 VALIDATION #3 START - TIME:0\n",
      "\n",
      "VALIDATION #3  Average Loss: 0.7532, mIoU: 0.4658, acc : 0.9137\n",
      "\n",
      "- FOLD:4 VALIDATION #3 DONE - TIME:114.32412028312683\n",
      "\n",
      "[mIoU] Best performance at epoch: 3\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:4 Epoch:3 Training DONE - TIME:792.0455622673035\n",
      "\n",
      "- Fold:4 Epoch:4 Training Start - TIME:0\n",
      "\n",
      "Epoch [4/20], Step [25/164], Loss: 0.8005\n",
      "Epoch [4/20], Step [50/164], Loss: 0.8218\n",
      "Epoch [4/20], Step [75/164], Loss: 0.7911\n",
      "Epoch [4/20], Step [100/164], Loss: 0.7626\n",
      "Epoch [4/20], Step [125/164], Loss: 0.6950\n",
      "Epoch [4/20], Step [150/164], Loss: 0.7680\n",
      "\n",
      "- FOLD:4 VALIDATION #4 START - TIME:0\n",
      "\n",
      "VALIDATION #4  Average Loss: 0.7442, mIoU: 0.4629, acc : 0.9174\n",
      "\n",
      "- FOLD:4 VALIDATION #4 DONE - TIME:114.69395804405212\n",
      "\n",
      "- Fold:4 Epoch:4 Training DONE - TIME:795.9348096847534\n",
      "\n",
      "- Fold:4 Epoch:5 Training Start - TIME:0\n",
      "\n",
      "Epoch [5/20], Step [25/164], Loss: 0.6817\n",
      "Epoch [5/20], Step [50/164], Loss: 0.7430\n",
      "Epoch [5/20], Step [75/164], Loss: 0.7592\n",
      "Epoch [5/20], Step [100/164], Loss: 0.6868\n",
      "Epoch [5/20], Step [125/164], Loss: 0.7091\n",
      "Epoch [5/20], Step [150/164], Loss: 0.7547\n",
      "\n",
      "- FOLD:4 VALIDATION #5 START - TIME:0\n",
      "\n",
      "VALIDATION #5  Average Loss: 0.7430, mIoU: 0.5136, acc : 0.9200\n",
      "\n",
      "- FOLD:4 VALIDATION #5 DONE - TIME:116.61714577674866\n",
      "\n",
      "[mIoU] Best performance at epoch: 5\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:4 Epoch:5 Training DONE - TIME:792.4397222995758\n",
      "\n",
      "- Fold:4 Epoch:6 Training Start - TIME:0\n",
      "\n",
      "Epoch [6/20], Step [25/164], Loss: 0.6656\n",
      "Epoch [6/20], Step [50/164], Loss: 0.6665\n",
      "Epoch [6/20], Step [75/164], Loss: 0.6871\n",
      "Epoch [6/20], Step [100/164], Loss: 0.7402\n",
      "Epoch [6/20], Step [125/164], Loss: 0.7805\n",
      "Epoch [6/20], Step [150/164], Loss: 0.7067\n",
      "\n",
      "- FOLD:4 VALIDATION #6 START - TIME:0\n",
      "\n",
      "VALIDATION #6  Average Loss: 0.7325, mIoU: 0.5342, acc : 0.9208\n",
      "\n",
      "- FOLD:4 VALIDATION #6 DONE - TIME:113.20695900917053\n",
      "\n",
      "[mIoU] Best performance at epoch: 6\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:4 Epoch:6 Training DONE - TIME:789.4775133132935\n",
      "\n",
      "- Fold:4 Epoch:7 Training Start - TIME:0\n",
      "\n",
      "Epoch [7/20], Step [25/164], Loss: 0.6662\n",
      "Epoch [7/20], Step [50/164], Loss: 0.6637\n",
      "Epoch [7/20], Step [75/164], Loss: 0.7684\n",
      "Epoch [7/20], Step [100/164], Loss: 0.6953\n",
      "Epoch [7/20], Step [125/164], Loss: 0.6953\n",
      "Epoch [7/20], Step [150/164], Loss: 0.6732\n",
      "\n",
      "- FOLD:4 VALIDATION #7 START - TIME:0\n",
      "\n",
      "VALIDATION #7  Average Loss: 0.7443, mIoU: 0.5176, acc : 0.9190\n",
      "\n",
      "- FOLD:4 VALIDATION #7 DONE - TIME:111.59767770767212\n",
      "\n",
      "- Fold:4 Epoch:7 Training DONE - TIME:784.9087421894073\n",
      "\n",
      "- Fold:4 Epoch:8 Training Start - TIME:0\n",
      "\n",
      "Epoch [8/20], Step [25/164], Loss: 0.6774\n",
      "Epoch [8/20], Step [50/164], Loss: 0.7429\n",
      "Epoch [8/20], Step [75/164], Loss: 0.6701\n",
      "Epoch [8/20], Step [100/164], Loss: 0.6994\n",
      "Epoch [8/20], Step [125/164], Loss: 0.6970\n",
      "Epoch [8/20], Step [150/164], Loss: 0.6994\n",
      "\n",
      "- FOLD:4 VALIDATION #8 START - TIME:0\n",
      "\n",
      "VALIDATION #8  Average Loss: 0.7514, mIoU: 0.5242, acc : 0.9172\n",
      "\n",
      "- FOLD:4 VALIDATION #8 DONE - TIME:121.81563377380371\n",
      "\n",
      "- Fold:4 Epoch:8 Training DONE - TIME:802.7068405151367\n",
      "\n",
      "- Fold:4 Epoch:9 Training Start - TIME:0\n",
      "\n",
      "Epoch [9/20], Step [25/164], Loss: 0.7396\n",
      "Epoch [9/20], Step [50/164], Loss: 0.6358\n",
      "Epoch [9/20], Step [75/164], Loss: 0.6875\n",
      "Epoch [9/20], Step [100/164], Loss: 0.6424\n",
      "Epoch [9/20], Step [125/164], Loss: 0.6507\n",
      "Epoch [9/20], Step [150/164], Loss: 0.7386\n",
      "\n",
      "- FOLD:4 VALIDATION #9 START - TIME:0\n",
      "\n",
      "VALIDATION #9  Average Loss: 0.7549, mIoU: 0.5357, acc : 0.9180\n",
      "\n",
      "- FOLD:4 VALIDATION #9 DONE - TIME:111.18601083755493\n",
      "\n",
      "[mIoU] Best performance at epoch: 9\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:4 Epoch:9 Training DONE - TIME:817.9211277961731\n",
      "\n",
      "- Fold:4 Epoch:10 Training Start - TIME:0\n",
      "\n",
      "Epoch [10/20], Step [25/164], Loss: 0.6972\n",
      "Epoch [10/20], Step [50/164], Loss: 0.6365\n",
      "Epoch [10/20], Step [75/164], Loss: 0.6658\n",
      "Epoch [10/20], Step [100/164], Loss: 0.6592\n",
      "Epoch [10/20], Step [125/164], Loss: 0.6881\n",
      "Epoch [10/20], Step [150/164], Loss: 0.7096\n",
      "\n",
      "- FOLD:4 VALIDATION #10 START - TIME:0\n",
      "\n",
      "VALIDATION #10  Average Loss: 0.7304, mIoU: 0.5424, acc : 0.9265\n",
      "\n",
      "- FOLD:4 VALIDATION #10 DONE - TIME:112.66475248336792\n",
      "\n",
      "[mIoU] Best performance at epoch: 10\n",
      "Save model in /opt/ml/code/saved/mlskf_aug\n",
      "\n",
      "- Fold:4 Epoch:10 Training DONE - TIME:796.1992557048798\n",
      "\n",
      "- Fold:4 Epoch:11 Training Start - TIME:0\n",
      "\n",
      "Epoch [11/20], Step [25/164], Loss: 0.6263\n",
      "Epoch [11/20], Step [50/164], Loss: 0.7230\n",
      "Epoch [11/20], Step [75/164], Loss: 0.7492\n",
      "Epoch [11/20], Step [100/164], Loss: 0.6283\n",
      "Epoch [11/20], Step [125/164], Loss: 0.6222\n",
      "Epoch [11/20], Step [150/164], Loss: 0.6193\n",
      "\n",
      "- FOLD:4 VALIDATION #11 START - TIME:0\n",
      "\n",
      "VALIDATION #11  Average Loss: 0.7493, mIoU: 0.5185, acc : 0.9198\n",
      "\n",
      "- FOLD:4 VALIDATION #11 DONE - TIME:108.87341356277466\n",
      "\n",
      "- Fold:4 Epoch:11 Training DONE - TIME:789.2661850452423\n",
      "\n",
      "- Fold:4 Epoch:12 Training Start - TIME:0\n",
      "\n",
      "Epoch [12/20], Step [25/164], Loss: 0.6791\n",
      "Epoch [12/20], Step [50/164], Loss: 0.6699\n",
      "Epoch [12/20], Step [75/164], Loss: 0.6399\n",
      "Epoch [12/20], Step [100/164], Loss: 0.6299\n",
      "Epoch [12/20], Step [125/164], Loss: 0.6304\n",
      "Epoch [12/20], Step [150/164], Loss: 0.6645\n",
      "\n",
      "- FOLD:4 VALIDATION #12 START - TIME:0\n",
      "\n",
      "VALIDATION #12  Average Loss: 0.7479, mIoU: 0.5195, acc : 0.9191\n",
      "\n",
      "- FOLD:4 VALIDATION #12 DONE - TIME:114.95443868637085\n",
      "\n",
      "- Fold:4 Epoch:12 Training DONE - TIME:801.4439568519592\n",
      "\n",
      "- Fold:4 Epoch:13 Training Start - TIME:0\n",
      "\n",
      "Epoch [13/20], Step [25/164], Loss: 0.6256\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/opt/ml/input/data/train_all.json'\n",
    "alldata = pd.read_csv('/opt/ml/code/alldata.csv')\n",
    "\n",
    "MLSKF(alldata,data_dir,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K Fold\n",
    "- by = bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/train_all.json'\n",
    "\n",
    "def SKF(dataframe=pd.read_csv('/opt/ml/code/alldata.csv'),data_dir='/opt/ml/input/data/train_all.json',n_splits=5):\n",
    "\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from pytorch_toolbelt import losses as L\n",
    "\n",
    "    encoder_name = \"se_resnext101_32x4d\"\n",
    "    encoder_weights = \"imagenet\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    saved_dir = '/opt/ml/code/saved/skf'\n",
    "\n",
    "    # bin 기준 나누기\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    folds = skf.split(dataframe.values, y=dataframe['bin'].values)\n",
    "\n",
    "    for i, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # fold별 모델\n",
    "        model = get_model(encoder_name,encoder_weights)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 데이터 로더\n",
    "        train_dataloader, valid_dataloader = get_train_valid_dataloader(dataframe, trn_idx, val_idx,fold=i+1)\n",
    "\n",
    "        # loss\n",
    "        # criterion = nn.CrossEntropyLoss()\n",
    "        # criterion = L.FocalLoss()\n",
    "        criterion = L.SoftCrossEntropyLoss(smooth_factor = 0.1) \n",
    "\n",
    "        # optimizer\n",
    "        optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)\n",
    "\n",
    "        # 학습\n",
    "        train(fold=i+1,\n",
    "              num_epochs=20, \n",
    "              model=model, \n",
    "              train_dataloader=train_dataloader, \n",
    "              valid_dataloader=valid_dataloader, \n",
    "              criterion=criterion, \n",
    "              optimizer=optimizer, \n",
    "              saved_dir=saved_dir, \n",
    "              val_every=val_every, \n",
    "              device=device, \n",
    "              encoder_name=encoder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '/opt/ml/input/data/train_all.json'\n",
    "# alldata = pd.read_csv('/opt/ml/code/alldata.csv')\n",
    "\n",
    "# SKF(alldata,data_dir,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(folder_path):\n",
    "\n",
    "    from glob import glob\n",
    "    from scipy import stats\n",
    "\n",
    "    model_list = glob(folder_path + '/*')\n",
    "    test = pd.read_csv('/opt/ml/code/testdata.csv')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    size = 256\n",
    "\n",
    "    n_folds = len(model_list)\n",
    "\n",
    "    soft_voting = [] # Fold,Data,12,256,256\n",
    "    hard_voting = [] # Fold,Data,256,256\n",
    "    \n",
    "\n",
    "    for fold in range(n_folds):\n",
    "\n",
    "        print(f'\\n@@@@@@@@@ FOLD {fold+1} INFERENCE START @@@@@@@@@ - TIME:0\\n')\n",
    "        start_time = time.time()\n",
    "        \n",
    "        file_name_list = []\n",
    "        preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "        one_soft = [] # Data,12,256,256\n",
    "\n",
    "        print(f'\\n- FOLD {fold+1} DATASET LOAD START -\\n')\n",
    "        test_dataloader = get_test_dataloader(test)\n",
    "        model = torch.load(model_list[fold])\n",
    "        model.eval()\n",
    "        print(f'\\n- FOLD {fold+1} DATASET LOAD DONE -\\n')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (imgs, image_infos) in enumerate(test_dataloader):\n",
    "                \n",
    "                if (step+1)%5==0 or step+1==len(test_dataloader):\n",
    "                    print(f'STEP [{step+1}/{len(test_dataloader)}]')\n",
    "                \n",
    "                # inference (512 x 512)\n",
    "                # outs = model(torch.stack(imgs).to(device)) # batch, 12, 512, 512\n",
    "                outs = model(torch.stack(imgs).float().to(device)) # batch, 12, 512, 512\n",
    "\n",
    "                ######### soft voting #########\n",
    "                soft = outs.detach().cpu().numpy()\n",
    "                soft = soft.transpose(0,2,3,1)\n",
    "                \n",
    "                channel_list = []\n",
    "                for image in soft:\n",
    "                    transformed_mask = test_transform(image=image)['image']\n",
    "                    channel_list.append(transformed_mask)\n",
    "\n",
    "                # (batch, 12, 256, 256)\n",
    "                soft = torch.stack(channel_list)\n",
    "                soft = soft.numpy()\n",
    "                \n",
    "                one_soft.append(soft)\n",
    "                ################################\n",
    "\n",
    "                ######### hard voting #########\n",
    "                oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "                \n",
    "                # resize (256 x 256)\n",
    "                temp_mask = []\n",
    "                for img, mask in zip(np.stack(imgs), oms):\n",
    "                    transformed = A.Compose([A.Resize(size, size)])(image=img, mask=mask)\n",
    "                    mask = transformed['mask']\n",
    "                    temp_mask.append(mask)\n",
    "\n",
    "                oms = np.array(temp_mask)\n",
    "                \n",
    "                oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "                preds_array = np.vstack((preds_array, oms))\n",
    "\n",
    "                file_name_list.append([i for i in image_infos])\n",
    "                \n",
    "        # soft voting\n",
    "        one_soft = np.array(one_soft)\n",
    "        one_soft = np.concatenate(one_soft)\n",
    "        soft_voting.append(one_soft)\n",
    "        print(f'soft voting size: {one_soft.shape}')\n",
    "\n",
    "        # hard voting\n",
    "        hard_voting.append(preds_array)\n",
    "        print(f'hard voting size: {preds_array.shape}')\n",
    "        print(f'\\n@@@@@@@@@ FOLD {fold+1} INFERENCE DONE @@@@@@@@@ - TIME:{time.time()-start_time}\\n')\n",
    "        \n",
    "        # file names\n",
    "        if fold == 1:\n",
    "            file_names = [y for x in file_name_list for y in x]\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return file_names, soft_voting, hard_voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set에 대한 prediction\n",
    "folder_path = '/opt/ml/code/saved/mlskf_aug'\n",
    "encoder_name = \"se_resnext101_32x4d\"\n",
    "file_names, soft_voting, hard_voting = inference(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_process(soft_voting,hard_voting,size):\n",
    "    print(f'\\n---------- SOFT VOTING START ---------- TIME:0\\n')\n",
    "    start_time = time.time()\n",
    "    soft_voting = np.concatenate(soft_voting,axis=0,dtype=np.float16) # Fold,Data,12,256,256\n",
    "    print(soft_voting.shape)\n",
    "    soft_voting = np.sum(soft_voting, axis=0) # Data,12,256,256\n",
    "    soft_voting = np.argmax(soft_voting, axis=1) # Data,256,256\n",
    "    soft_voting = soft_voting.reshape([soft_voting.shape[0], size*size]).astype(int)# Data,256*256\n",
    "    print(f'\\n---------- SOFT VOTING DONE ---------- TIME:{time.time()-start_time}\\n')\n",
    "    print(f'\\n---------- HARD VOTING START ---------- TIME:0\\n')\n",
    "    start_time = time.time()\n",
    "    hard_voting = np.array(hard_voting) # Fold,Data,256*256\n",
    "    hard_voting = stats.mode(hard_voting)[0] # Data,256*256\n",
    "    hard_voting = np.squeeze(hard_voting)\n",
    "    print(f'\\n---------- HARD VOTING DONE ---------- TIME:{time.time()-start_time}')\n",
    "    return soft_voting, hard_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256\n",
    "soft_voting, hard_voting = ensemble_process(soft_voting, hard_voting, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "for file_name, string in tqdm(zip(file_names, soft_voting)):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "submission.to_csv(f\"/opt/ml/code/submission/{encoder_name}(pretrained)_soft_voting.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softdata = pd.read_csv(f\"/opt/ml/code/submission/{encoder_name}(pretrained)_soft_voting.csv\")\n",
    "softdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "    \n",
    "for file_name, string in tqdm(zip(file_names, hard_voting)):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "submission.to_csv(f\"/opt/ml/code/submission/{encoder_name}(pretrained)_hard_voting.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harddata = pd.read_csv(f\"/opt/ml/code/submission/{encoder_name}(pretrained)_hard_voting.csv\")\n",
    "harddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.278px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
